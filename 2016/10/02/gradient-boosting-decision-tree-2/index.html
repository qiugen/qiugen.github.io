<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="enjoy"><title>gradient boosting decision tree[下篇] | 水滴石穿</title><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/4.2.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/grids-responsive-min.css"><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.0.0/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">gradient boosting decision tree[下篇]</h1><a id="logo" href="/.">水滴石穿</a><p class="description">无止境探索，保持渴望，无所畏惧</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">gradient boosting decision tree[下篇]</h1><div class="post-meta">Oct 2, 2016<span> | </span><span class="category"><a href="/categories/机器学习/">机器学习</a></span><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> Hits</span></span></div><a data-thread-key="2016/10/02/gradient-boosting-decision-tree-2/" href="/2016/10/02/gradient-boosting-decision-tree-2/#comments" class="ds-thread-count"></a><div class="post-content"><p>&#x8FD9;&#x7BC7;&#x7B14;&#x8BB0;&#x91CC;&#x9762;&#x4F1A;&#x7EE7;&#x7EED;&#x4ECB;&#x7ECD;<a href="https://qiugen.github.io/2016/09/24/gradient-boosting-decision-tree-1/">&#x4E0A;&#x7BC7;</a>GB&#x7406;&#x8BBA;&#x7684;&#x5177;&#x4F53;&#x7528;&#x6CD5;&#xFF0C;&#x5BF9;&#x4E0D;&#x540C;&#x7684;<code>loss function</code>&#x5C55;&#x5F00;&#x8BA8;&#x8BBA;&#xFF1A;&#x6700;&#x5C0F;&#x5747;&#x65B9;&#x8BEF;&#x5DEE;(LS)&#x548C;&#x6700;&#x5C0F;&#x7EDD;&#x5BF9;&#x503C;&#x8BEF;&#x5DEE;(LAD)&#xFF0C;Huber(M)&#x51FD;&#x6570;&#xFF0C;&#x4E09;&#x8005;&#x4E3B;&#x8981;&#x662F;&#x7528;&#x5728;&#x56DE;&#x5F52;&#x95EE;&#x9898;&#x3002;&#x63A5;&#x7740;&#x518D;&#x770B;GB&#x7406;&#x8BBA;&#x600E;&#x4E48;&#x7528;&#x5728;&#x4E8C;&#x5206;&#x7C7B;&#x548C;&#x591A;&#x5206;&#x7C7B;&#x4E0A;&#x3002;</p>
<blockquote>
<p>&#x6709;&#x6CA1;&#x6709;&#x53D1;&#x73B0;&#x5199;&#x4E86;&#x8FD9;&#x4E48;&#x591A;&#xFF0C;&#x8FD8;&#x662F;&#x6CA1;&#x6709;&#x70B9;&#x9898;&#x201D;GBDT&#x201D;&#xFF0C;&#x5148;&#x8BB0;&#x4E0B;&#xFF0C;&#x4E14;&#x5F80;&#x4E0B;&#x770B;<br>&#x7EB8;&#x4E0A;&#x5F97;&#x6765;&#x7EC8;&#x89C9;&#x6D45;&#xFF0C;&#x5E0C;&#x671B;&#x80FD;&#x7EC4;&#x7EC7;&#x4E00;&#x6CE2;&#x5C0F;&#x4F19;&#x4F34;&#x628A;&#x6A21;&#x578B;&#x5B9E;&#x73B0;&#x4E2A;&#x904D;&#x561E;</p>
</blockquote>
<p>&#x56DE;&#x987E;&#x4E0B;&#xFF1A;&#x4E0A;&#x4E00;&#x7BC7;&#x7ED3;&#x5C3E;&#x90E8;&#x5206;&#xFF0C;&#x6211;&#x4EEC;&#x7ED9;&#x51FA;&#x4E86;&#x901A;&#x7528;&#x7684;GB&#x6846;&#x67B6;&#xFF1A;</p>
<ol>
<li>${F_0}\left( {\bf{x}} \right) = \arg {\min _\rho }\sum\nolimits_{i = 1}^N {L\left( {{y_i},\rho } \right)} $</li>
<li>$For\;m = 1\;to\;M\;do:$</li>
<li>${{\tilde y}_i} =  - {\left[ {{{\partial L\left( {{y_i},F\left( {{{\bf{x}}_i}} \right)} \right)} \over {\partial F\left( {{{\bf{x}}_i}} \right)}}} \right]_{F\left( {\bf{x}} \right) = {F_{m - 1}}\left( {\bf{x}} \right)}},i = 1,N$</li>
<li>${{\bf{a}}_m} = \arg {\min _{{\bf{a}},\beta }}{\sum\nolimits_{i = 1}^N {\left[ {{{\tilde y}_i} - \beta h\left( {{{\bf{x}}_i};{\bf{a}}} \right)} \right]} ^2}$</li>
<li>${\rho _m} = \arg \mathop {\min }\limits_\rho  \sum\nolimits_{i = 1}^N {L\left( {{y_i},{F_{m - 1}}\left( {{{\bf{x}}_i}} \right) + \rho h\left( {{{\bf{x}}_i};{{\bf{a}}_m}} \right)} \right)} $</li>
<li>${F_m}\left( {\bf{x}} \right) = {F_{m - 1}}\left( {\bf{x}} \right) + {\rho _m}h\left( {{\bf{x}};{{\bf{a}}_m}} \right)$</li>
<li>$end For$
</li>
</ol>
<p>&#x5C06;&#x82E5;&#x5E72;learner $h({\bf x}_i;{\bf a})$&#x7528;mixture&#x65B9;&#x5F0F;&#x8FDB;&#x884C;&#x7EC4;&#x5408;&#x6700;&#x5C0F;&#x5316;<em>loss function</em>&#xFF0C;&#x6839;&#x636E;&#x4E0D;&#x540C;&#x7684;<em>loss function</em>&#xFF0C;&#x7B2C;4&#x884C;&#x7684;&#x8D1F;&#x68AF;&#x5EA6;&#x8BA1;&#x7B97;&#x4E5F;&#x4E0D;&#x540C;&#xFF0C;&#x4E0B;&#x9762;&#x4ECB;&#x7ECD;&#x4E0B;&#x51E0;&#x4E2A;&#x5E38;&#x7528;&#x7684;<em>loss function</em>&#xFF1A;</p>
<h4 id="&#x6700;&#x5C0F;&#x5747;&#x65B9;&#x5DEE;-LS-&#x56DE;&#x5F52;"><a href="#&#x6700;&#x5C0F;&#x5747;&#x65B9;&#x5DEE;-LS-&#x56DE;&#x5F52;" class="headerlink" title="&#x6700;&#x5C0F;&#x5747;&#x65B9;&#x5DEE;(LS)&#x56DE;&#x5F52;"></a><strong>&#x6700;&#x5C0F;&#x5747;&#x65B9;&#x5DEE;(LS)&#x56DE;&#x5F52;</strong></h4><p><em>loss function</em>&#x4E3A;$L\left( {y,F} \right) = {{{{\left( {y - F} \right)}^2}} \over 2}$&#x3002;&#x5728;$m$&#x8F6E;&#x5BF9;$F_{m-1}$&#x6C42;&#x5BFC;&#x5F97;&#x5230;&#x68AF;&#x5EA6;&#xFF0C;&#x8D1F;&#x68AF;&#x5EA6;<em>pseudore-response</em>&#x4E3A;${{\tilde y}_i} = {y_i} - {F_{m - 1}}\left( {{{\bf{x}}_i}} \right)$&#x3002;&#x901A;&#x7528;&#x6846;&#x67B6;&#x4E2D;&#x7B2C;4&#x884C;&#x53EA;&#x9700;&#x8981;&#x7B80;&#x5355;&#x5730;&#x62DF;&#x5408;&#x5F53;&#x524D;&#x7684;&#x6B8B;&#x5DEE;&#xFF0C;&#x7B2C;5&#x884C;&#x7EBF;&#x641C;&#x7D22;&#x6B65;&#x957F;$\rho _m$&#x53EF;&#x4EE5;&#x7B49;&#x4EF7;&#x4E3A;&#x7B2C;4&#x884C;&#x4E2D;&#x7684;$\beta _m$&#x3002;&#x4EE5;&#x6700;&#x5C0F;&#x5747;&#x65B9;&#x5DEE;&#x4E3A;<em>loss function</em>&#x7684;&#x53EF;&#x4EE5;&#x63A8;&#x51FA;&#x6B8B;&#x5DEE;&#x62DF;&#x5408;&#x7684;&#x7EA7;&#x8054;&#x65B9;&#x6CD5;&#xFF0C;&#x8FD9;&#x4E5F;&#x662F;&#x6700;&#x5E38;&#x89C1;&#x7684;&#x5F62;&#x5F0F;&#x3002;LS_Boost&#x6D41;&#x7A0B;&#x6574;&#x7406;&#x5982;&#x4E0B;&#xFF1A;<br>$$\eqalign{
  &amp; For\;m = 1\;to\;M\;do:  \cr 
  &amp; \;\;\;\;{y_i} = {y_i} - {F_{m - 1}}\left( {{{\bf{x}}_i}} \right),\;i = 1,N  \cr 
  &amp; \;\;\;\;\left( {{\rho _m},{{\bf{a}}_m}} \right) = \mathop {\arg \min }\limits_{{\bf{a}},\rho } {\sum\limits_{i = 1}^N {\left[ {{{\tilde y}_i} - \rho h\left( {{{\bf{x}}_i};{\bf{a}}} \right)} \right]} ^2}  \cr 
  &amp; \;\;\;\;{F_m}\left( {\bf{x}} \right) = {F_{m - 1}}\left( {\bf{x}} \right) + {\rho _m}h\left( {{\bf{x}};{{\bf{a}}_m}} \right)  \cr 
  &amp; endFor\; \cr} $$</p>
<h4 id="&#x6700;&#x5C0F;&#x7EDD;&#x5BF9;&#x503C;&#x8BEF;&#x5DEE;-LAD-&#x56DE;&#x5F52;"><a href="#&#x6700;&#x5C0F;&#x7EDD;&#x5BF9;&#x503C;&#x8BEF;&#x5DEE;-LAD-&#x56DE;&#x5F52;" class="headerlink" title="&#x6700;&#x5C0F;&#x7EDD;&#x5BF9;&#x503C;&#x8BEF;&#x5DEE;(LAD)&#x56DE;&#x5F52;"></a><strong>&#x6700;&#x5C0F;&#x7EDD;&#x5BF9;&#x503C;&#x8BEF;&#x5DEE;(LAD)&#x56DE;&#x5F52;</strong></h4><p><em>loss function</em> &#x4E3A;$L\left( {y,F} \right) = \left| {y - F} \right|\;$&#xFF0C;&#x53EF;&#x4EE5;&#x5F97;&#x5230;&#x8D1F;&#x68AF;&#x5EA6;&#x4E3A;<em>pseudore-response</em><br>$${{\tilde y}_i} =  - {\left[ {{{\partial L\left( {{y_i},F\left( {{{\bf{x}}_i}} \right)} \right)} \over {\partial F\left( {{{\bf{x}}_i}} \right)}}} \right]_{F\left( {\bf{x}} \right){\rm{ = }}{F_{m - 1}}\left( {\bf{x}} \right)}} = sign\left( {{y_i} - {F_{m - 1}}\left( {{{\bf{x}}_i}} \right)} \right)$$&#xFF0C;&#x8FD9;&#x4E2A;&#x6C42;&#x5BFC;&#x8FC7;&#x7A0B;&#x653E;&#x5728;&#x9644;&#x5F55;&#x601D;&#x8003;[1]&#x3002;<br>&#x6211;&#x4EEC;&#x9700;&#x8981;&#x4E00;&#x7EC4;&#x5206;&#x7C7B;&#x5668;$h({\bf x};{\bf a})$&#x53BB;&#x62DF;&#x5408;&#x6B8B;&#x5DEE;&#x7684;&#x7B26;&#x53F7;&#xFF08;pseudore-response&#x4E3A;&#x7B26;&#x53F7;&#x51FD;&#x6570;&#x503C;&#xFF0C;&#x62DF;&#x5408;pseudore-response&#x5373;&#x62DF;&#x5408;&#x6B8B;&#x5DEE;&#x7684;&#x7B26;&#x53F7;&#xFF09;&#x3002;&#x901A;&#x8FC7;&#x7EBF;&#x641C;&#x7D22;&#x5F97;&#x5230;<br>$$\eqalign{
  &amp; {\rho _m} = \arg \mathop {\min }\limits_\rho  \sum\limits_{i = 1}^N {\left| {{y_i} - {F_{m - 1}}\left( {{{\bf{x}}_i}} \right) - \rho h\left( {{{\bf{x}}_i};{{\bf{a}}_m}} \right)} \right|}   \cr 
  &amp; {\kern 1pt} \;\;\;\; = \arg \mathop {\min }\limits_\rho  \sum\limits_{i = 1}^N {\left| {h\left( {{{\bf{x}}_i};{{\bf{a}}_m}} \right)} \right| \cdot \left| {{{{y_i} - {F_{m - 1}}\left( {{{\bf{x}}_i}} \right)} \over {h\left( {{{\bf{x}}_i};{{\bf{a}}_m}} \right)}} - \rho } \right|}   \cr 
  &amp; \;\;\;\;{\rm{ = media}}{{\rm{n}}_W}\left\{ {{{{y_i} - {F_{m - 1}}\left( {{{\bf{x}}_i}} \right)} \over {h\left( {{{\bf{x}}_i};{{\bf{a}}_m}} \right)}}} \right\}_1^N,{w_i} = \left| {h\left( {{{\bf{x}}_i};{{\bf{a}}_m}} \right)} \right|. \cr} $$<br>$media{n_W}\left\{ {} \right\}$&#x8868;&#x793A;&#x5148;&#x8FDB;&#x884C;$w_i$&#x52A0;&#x6743;&#xFF0C;&#x5728;&#x5F97;&#x5230;&#x7684;&#x7ED3;&#x679C;&#x4E2D;&#xFF0C;&#x53D6;&#x5F97;&#x4E2D;&#x4F4D;&#x6570;&#x3002;&#x6211;&#x4EEC;&#x5728;GB&#x8FC7;&#x7A0B;&#x4E2D;&#xFF0C;&#x91C7;&#x7528;&#x4E0A;&#x9762;&#x7684;<em>pseudore-response</em>&#x548C;$h({\bf x};{\bf a})$&#x3001;&#x4EE5;&#x53CA;&#x6B65;&#x957F;$\rho_m$&#xFF0C;&#x53EF;&#x4EE5;&#x5F97;&#x5230;<em>loss function</em>&#x4E3A;LAD&#x7684;GB&#x7B97;&#x6CD5;&#x3002;</p>
<h4 id="&#x7528;&#x4E8E;&#x56DE;&#x5F52;&#x7684;GBDT"><a href="#&#x7528;&#x4E8E;&#x56DE;&#x5F52;&#x7684;GBDT" class="headerlink" title="&#x7528;&#x4E8E;&#x56DE;&#x5F52;&#x7684;GBDT"></a><strong>&#x7528;&#x4E8E;&#x56DE;&#x5F52;&#x7684;GBDT</strong></h4><p>&#x4E0A;&#x9762;&#x4ECB;&#x7ECD;&#x4E86;GB&#x65B9;&#x6CD5;&#x4E2D;&#x7684;LS&#x548C;LAD&#xFF0C;&#x5982;&#x679C;&#x4F7F;&#x7528;&#x6811;&#x6A21;&#x578B;&#x4F8B;&#x5982;CART&#x6811;&#x4F5C;&#x4E3A;$h({\bf x};{\bf a})$&#xFF0C;&#x53EF;&#x4EE5;&#x8868;&#x8FF0;&#x5982;&#x4E0B;&#xFF1A;$$h\left( {{\bf{x}};\left\{ {{b_j},{R_j}} \right\}_1^J} \right) = \sum\limits_{j = 1}^J {{b_j}1\left( {{\bf{x}} \in {R_j}} \right)} $$<br>$\left\{ {{R_j}} \right\}_1^J$&#x8868;&#x793A;&#x4ECE;&#x89C2;&#x6D4B;&#x6570;&#x636E;$\bf x$&#x4E2D;&#x751F;&#x6210;&#x7684;&#x4E0D;&#x8054;&#x901A;&#x533A;&#x57DF;&#xFF0C;&#x7531;&#x6811;&#x7684;&#x5206;&#x88C2;&#x8282;&#x70B9;&#x8FDB;&#x884C;&#x5212;&#x5206;&#x3002;&#x800C;$$1\left(  \cdot  \right)$$&#xFF0C;&#x8868;&#x793A;&#x4E8B;&#x4EF6;$x \in R_j$&#x662F;&#x5426;&#x53D1;&#x751F;&#xFF0C;&#x5224;&#x65AD;&#x6837;&#x672C;&#x70B9;&#x843D;&#x5728;&#x67D0;&#x4E2A;&#x5206;&#x652F;&#x3002;&#x6811;&#x7684;&#x53C2;&#x6570;&#x6709;&#x4E24;&#x90E8;&#x5206;&#xFF0C;&#x8282;&#x70B9;&#x7CFB;&#x6570;&#x4E3A;$\left\{ {{b_j}} \right\}_1^J$&#x3001;&#x8282;&#x70B9;&#xFF08;&#x5305;&#x542B;&#x9009;&#x62E9;&#x54EA;&#x4E2A;&#x8282;&#x70B9;&#x548C;&#x786E;&#x8BA4;&#x5B83;&#x8FDB;&#x884C;&#x5206;&#x88C2;&#x7684;&#x503C;&#xFF09;&#x3002;&#x56DE;&#x5F52;&#x6811;&#x7684;&#x66F4;&#x65B0;&#x516C;&#x5F0F;&#x4E3A;&#xFF1A;<br>$${F_m}\left( {\bf{x}} \right) = {F_{m - 1}}\left( {\bf{x}} \right) + {\rho _m}\sum\limits_{j = 1}^J {{b_{jm}}1\left( {{\bf{x}} \in {R_{jm}}} \right)} --(1)$$<br>&#x8FD9;&#x91CC;$\left\{ {{R_{jm}}} \right\}_1^J$&#x8868;&#x793A;&#x7B2C;$m$&#x8F6E;&#x8FED;&#x4EE3;&#x4E2D;&#x6811;&#x7684;&#x8282;&#x70B9;&#x6240;&#x5212;&#x5206;&#x7684;&#x533A;&#x57DF;&#x3002;&#x82E5;&#x5BF9;&#x4E8E;<em>loss function</em>&#x4E3A;&#x6700;&#x5C0F;&#x5747;&#x65B9;&#x5DEE;(LS)&#xFF0C;&#x8FD9;&#x4E9B;&#x533A;&#x57DF;&#x7684;&#x7D2F;&#x52A0;&#x7528;&#x6765;&#x8868;&#x793A;&#x5F53;&#x524D;&#x7684;<em>pseudo-response</em>&#xFF0C;$\left\{ {{b_{jm}}} \right\}$&#x4E3A;&#x6700;&#x5C0F;&#x5747;&#x65B9;&#x5DEE;&#x7684;&#x7CFB;&#x6570;&#xFF1A;<br>$$b_{jm}=ave_{{\bf x}_i \in R_{jm}}{\tilde y}_i$$&#x3002;&#x6B65;&#x957F;$\rho_m$&#x540C;&#x4E0A;&#x8FF0;&#x4E00;&#x81F4;&#xFF0C;&#x53EF;&#x4EE5;&#x7EBF;&#x641C;&#x7D22;&#x8FDB;&#x884C;&#x6C42;&#x89E3;&#x3002;<br>&#x4F5C;&#x8005;&#x63D0;&#x4F9B;&#x4E86;&#x4E00;&#x79CD;&#x7B80;&#x5316;&#x65B9;&#x5F0F;&#xFF0C;&#x8BB0;${\gamma _{jm}} = {\rho _m}{b_{jm}}$&#x3002;$(1)$&#x5F0F;&#x53D8;&#x5316;&#x5982;&#x4E0B;&#xFF1A;<br>$${F_m}\left( {\bf{x}} \right) = {F_{m - 1}}\left( {\bf{x}} \right) + \sum\limits_{j = 1}^J {{\gamma _{jm}}1\left( {{\bf{x}} \in {R_{jm}}} \right)} $$<br>&#x4ECE;&#x4E0A;&#x9762;&#x516C;&#x5F0F;&#x51FA;&#x53D1;&#xFF0C;&#x6211;&#x4EEC;&#x53EF;&#x4EE5;&#x89C6;&#x4F5C;&#x6BCF;&#x7EA7;&#x589E;&#x52A0;$J$&#x4E2A;&#x4E0D;&#x540C;&#x7684;&#x57FA;&#x51FD;&#x6570;&#x3002;&#x5BF9;&#x8FD9;&#x6837;&#x7684;&#x5F0F;&#x5B50;&#xFF0C;&#x6211;&#x4EEC;&#x53EF;&#x4EE5;&#x901A;&#x8FC7;&#x4F18;&#x5316;&#x4E0B;&#x9762;&#x8FD9;&#x4E2A;&#x5F0F;&#x5B50;&#x5F97;&#x5230;&#x51FD;&#x6570;&#x53C2;&#x6570;&#xFF1A;$$\left\{ {{\gamma _{jm}}} \right\}_1^J = \arg \mathop {\min }\limits_{\left\{ {{\gamma _j}} \right\}_1^J} \sum\limits_{i = 1}^N {L\left( {{y_i},{F_{m - 1}}\left( {{{\bf{x}}_i}} \right) + \sum\limits_{j = 1}^J {{\gamma _j}1\left( {{\bf{x}} \in {R_{jm}}} \right)} } \right)} $$<br>&#x56E0;&#x4E3A;&#x57FA;&#x51FD;&#x6570;&#x4EE3;&#x8868;&#x7684;&#x6BCF;&#x4E2A;&#x533A;&#x57DF;&#x4E4B;&#x95F4;&#x4E0D;&#x76F8;&#x4E92;&#x4F9D;&#x8D56;&#xFF0C;&#x5BF9;&#x4E8E;&#x6BCF;&#x4E00;&#x7EA7;&#x53EF;&#x4EE5;&#x62C6;&#x5F00;&#x89C6;&#x4E3A;$j$&#x4E2A;&#x6700;&#x5C0F;&#x5355;&#x4F4D;&#x7684;&#x4F18;&#x5316;&#xFF1A;$${\gamma _{jm}} = \arg \mathop {\min }\limits_\gamma  \sum\limits_{{\bf x}_i \in R_{jm}}^N {L\left( {{y_i},{F_{m - 1}}\left( {{{\bf{x}}_i}} \right) + \gamma } \right)} --(2)$$<br>&#x7ED9;&#x5B9A;&#x5F53;&#x524D;&#x7684;&#x51FD;&#x6570;&#x903C;&#x8FD1;$F_{m-1}(x)$&#x5728;&#x6BCF;&#x4E2A;&#x8282;&#x70B9;&#x5212;&#x5206;&#x7684;&#x533A;&#x57DF;&#x4E0A;&#x4F18;&#x5316;&#xFF0C;&#x5728;LAD&#x7684;<em>loss function</em>&#x4E0B;$(2)$&#x53EF;&#x4EE5;&#x6F14;&#x53D8;&#x4E3A;&#xFF1A;$${\gamma _{jm}} = media{n_{{{\bf{x}}_i} \in {R_{jm}}}}\left\{ {{y_i} - {F_{m - 1}}\left( {{{\bf{x}}_i}} \right)} \right\}$$&#x3002;&#x7B2C;$m$&#x8F6E;&#x7B2C;$j$&#x8282;&#x70B9;&#x53C2;&#x6570;$\gamma$&#x53EF;&#x4EE5;&#x8868;&#x793A;&#x4E3A;&#x6B8B;&#x5DEE;&#x7684;&#x4E2D;&#x4F4D;&#x6570;&#x3002;&#x5728;&#x6BCF;&#x4E00;&#x8F6E;&#x8FED;&#x4EE3;&#x4E2D;&#x56DE;&#x5F52;&#x6811;&#x9884;&#x6D4B;&#x5F53;&#x524D;&#x6B8B;&#x5DEE;&#x7684;&#x4E2D;&#x4F4D;&#x6570;&#x3002;<br>$$\eqalign{
  &amp; {F_0}\left( {\bf{x}} \right) = median\left\{ {{y_i}} \right\}_1^N  \cr 
  &amp; For\;m = 1\;to\;M\;do:  \cr 
  &amp; \;\;\;\;{{\tilde y}_i} = {\mathop{\rm sign}\nolimits} \left( {{y_i} - {F_{m - 1}}\left( {{{\bf{x}}_i}} \right)} \right),i = 1,N  \cr 
  &amp; \;\;\;\;\left\{ {{R_{jm}}} \right\}_1^J = J - node\;tree\left( {\left\{ {{{\tilde y}_i},{{\bf{x}}_i}} \right\}_1^N} \right)  \cr 
  &amp; \;\;\;\;{\gamma _{jm}} = media{n_{{{\bf{x}}_i} \in {R_{jm}}}}\left\{ {{y_i} - {F_{m - 1}}\left( {{{\bf{x}}_i}} \right)} \right\},j = 1,J  \cr 
  &amp; \;\;\;\;{F_m}\left( {\bf{x}} \right) = {F_{m - 1}}\left( {\bf{x}} \right) + \sum\limits_{j = 1}^J {{\gamma _{jm}}1\left( {{\bf{x}} \in {R_{jm}}} \right)}   \cr 
  &amp; endFor \cr} $$<br>LAD&#x53EA;&#x7528;&#x4E86;&#x53D8;&#x91CF;&#x7684;&#x987A;&#x5E8F;&#x4FE1;&#x606F;&#xFF0C;<em>pseudo-response</em>&#x53EA;&#x6709;$\{-1,1\}$&#x4E8C;&#x503C;&#xFF0C;&#x7B97;&#x6CD5;&#x9C81;&#x68D2;&#x6027;&#x5F3A;&#xFF08;&#x6309;&#xFF0C;&#x4E2D;&#x4F4D;&#x6570;&#x5176;&#x5B9E;&#x633A;&#x96BE;&#x8BA1;&#x7B97;&#x7684;&#xFF0C;&#x89C1;&#x9644;&#x5F55;&#x601D;&#x8003;3&#xFF09;&#x5982;&#x679C;<em>loss function</em>&#x662F;&#x6700;&#x5C0F;&#x5747;&#x65B9;&#x8BEF;&#x5DEE;LS&#x7684;&#x8BDD;&#xFF0C;&#x90A3;&#x4E48;&#x6839;&#x636E;$(2)$&#x5F0F;&#x8FDB;&#x884C;&#x6C42;&#x5BFC;&#xFF0C;&#x53EF;&#x5F97;$\gamma$&#x66F4;&#x65B0;&#x516C;&#x5F0F;&#x3002;<br>&#x518D;&#x4ECB;&#x7ECD;&#x4E00;&#x79CD;&#x66F4;&#x76F4;&#x63A5;&#x7684;&#x601D;&#x8DEF;&#xFF0C;&#x8BAD;&#x7EC3;&#x4E00;&#x68F5;&#x6811;$tree$&#x76F4;&#x63A5;&#x62DF;&#x5408;LAD&#x7684;loss&#x3002;<br>$$tre{e_m}\left( {\bf{x}} \right) = \arg \mathop {\min }\limits_{J - node\;tree} \sum\limits_{i = 1}^N {\left| {{y_i} - {F_{m - 1}}\left( {{{\bf{x}}_i}} \right) - tree\left( {{{\bf{x}}_i}} \right)} \right|} $$<br>$${F_m}\left( {\bf{x}} \right) = {F_{m - 1}}\left( {\bf{x}} \right)+tree_{m}({\bf x})$$</p>
<h4 id="M-Regression&#xFF08;Huber-loss-function&#xFF09;"><a href="#M-Regression&#xFF08;Huber-loss-function&#xFF09;" class="headerlink" title="M-Regression&#xFF08;Huber loss function&#xFF09;"></a><strong>M-Regression&#xFF08;Huber loss function&#xFF09;</strong></h4><p>M-Regression&#x589E;&#x5F3A;&#x6A21;&#x578B;&#x5BF9;&#x957F;&#x5C3E;&#x7684;&#x8BEF;&#x5DEE;&#x5206;&#x5E03;&#x7684;&#x9C81;&#x68D2;&#x6027;&#xFF0C;&#x540C;&#x65F6;&#x4FDD;&#x6301;&#x5BF9;&#x6B63;&#x592A;&#x5206;&#x5E03;&#x8BEF;&#x5DEE;&#x8BA1;&#x7B97;&#x7684;&#x9AD8;&#x6548;&#x7387;&#x3002;</p>
<blockquote>
<p>&#x5F85;&#x7406;&#x89E3;&#x201D;M-regression techniques attempt resistance to longtailed error distributions and outliers while maintaining high efficiency for normally distributed errors&#x201D;</p>
</blockquote>
<p>&#x7ED9;&#x51FA;&#x4E0B;&#x9762;&#x7684;Huber <em>loss function</em>&#xFF1A;<br>$$L\left( {y,F} \right) = \left\{ {\matrix{
   {{1 \over 2}{{\left( {y - F} \right)}^2},\left| {y - F} \right| &lt; \delta }  \cr 
   {\delta \left( {\left| {y - F} \right| - {\delta  \over 2}} \right),\left| {y - F} \right| &gt; \delta }  \cr 
} } \right.$$<br>&#x6309;&#x524D;&#x8FF0;GB&#x6846;&#x67B6;&#xFF0C;&#x5148;&#x6C42;_pseudore<em>response</em>&#xFF1A;<br>$$\eqalign{
  &amp; {{\tilde y}_i} =  - {\left[ {{{\partial L\left( {{y_i},F\left( {{{\bf{x}}_i}} \right)} \right)} \over {\partial F\left( {{{\bf{x}}_i}} \right)}}} \right]_{F\left( {\bf{x}} \right) = {F_{m - 1}}\left( {\bf{x}} \right)}}  \cr 
  &amp; \;\;\;\; = \left\{ {\matrix{
   {{y_i} - {F_{m - 1}}\left( {{{\bf{x}}_i}} \right),\;\;\;\;\left| {{y_i} - {F_{m - 1}}\left( {{{\bf{x}}_i}} \right)} \right| \le \delta }  \cr 
   {\delta  \cdot {\mathop{\rm sign}\nolimits} \left( {{y_i} - {F_{m - 1}}\left( {{{\bf{x}}_i}} \right)} \right),\;\;\left| {{y_i} - {F_{m - 1}}\left( {{{\bf{x}}_i}} \right)} \right| \le \delta }  \cr } } \right. \cr} $$<br>&#x6839;&#x636E;<em>pseudo-response</em>&#x62DF;&#x5408;$h({\bf x}; {\bf a})$&#xFF1A;<br>$${\rho _m} = \arg \mathop {\min }\limits_\rho  \sum\limits_{i = 1}^N {L\left( {{y_i},{F_{m - 1}}\left( {{{\bf{x}}_i}} \right) + \rho h\left( {{{\bf{x}}_i};{{\bf{a}}_m}} \right)} \right)} $$<br>&#x5173;&#x4E8E;Huber &#x51FD;&#x6570;&#x5177;&#x4F53;&#x7EC6;&#x8282;&#x53C2;&#x770B;&#x5F15;&#x6587;[2]&#xFF0C;$\delta$&#x5B9A;&#x4E49;&#x4E86;&#x6B8B;&#x5DEE;&#x91CC;&#x9762;&#x54EA;&#x90E8;&#x5206;&#x5C5E;&#x4E8E;outlier&#xFF0C;&#x8FD9;&#x90E8;&#x5206;&#x4F7F;&#x7528;LAD&#x7EA6;&#x675F;&#xFF0C;&#x5176;&#x4ED6;&#x5219;&#x4F7F;&#x7528;LS&#x635F;&#x5931;&#x51FD;&#x6570;&#x7EA6;&#x675F;&#x3002;&#x771F;&#x5B9E;&#x7684;$\delta$&#x5E94;&#x7531;$y-F^*({\bf x})$&#x51B3;&#x5B9A;&#xFF0C;&#x5176;&#x4E2D;$F^*({\bf x})$&#x7531;&#x76EE;&#x6807;&#x51FD;&#x6570;&#x51B3;&#x5B9A;&#x3002;&#x5B9E;&#x8DF5;&#x4E2D;&#x901A;&#x5E38;&#x4F7F;&#x7528;$|y-F^*(x)|$&#x5206;&#x5E03;&#x7684;$\alpha$-&#x5206;&#x4F4D;&#x6570;&#x7684;&#x53D6;&#x503C;&#xFF1A;<br>$${\delta _m} = quantil{e_\alpha }\left\{ {\left| {{y_i} - {F_{m - 1}}\left( {{{\bf{x}}_i}} \right)} \right|} \right\}_1^N$$<br>&#x5173;&#x4E8E;&#x4E2D;&#x4F4D;&#x6570;&#x7684;&#x731C;&#x60F3;&#x89C1;&#x9644;&#x5F55;&#x601D;&#x8003;4&#x3002;<br>&#x5F97;&#x5230;&#x7B2C;$M$&#x8F6E;&#x7684;<em>pseudo-response</em>&#x4E4B;&#x540E;&#x6211;&#x4EEC;&#x7528;&#x4E00;&#x9897;&#x56DE;&#x5F52;&#x6811;&#x8FDB;&#x884C;&#x62DF;&#x5408;&#x3002;&#x5728;&#x7B2C;$j$&#x4E2A;&#x8282;&#x70B9;$R_{jm}$&#xFF0C;Huber loss&#x5173;&#x4E8E;&#x516C;&#x5F0F;$(2)$&#x7684;&#x89E3;&#x53EF;&#x4EE5;&#x4E00;&#x6B65;&#x6807;&#x51C6;&#x8FED;&#x4EE3;&#x8FC7;&#x7A0B;&#x8FDB;&#x884C;&#x8FD1;&#x4F3C;&#x3002;&#x5148;&#x5F97;&#x5230;&#x8282;&#x70B9;$R_{jm}$&#x4E0A;&#x6B8B;&#x5DEE;$\{r_{m-1}({\bf x}_i)\}^N_i$&#x4E2D;&#x4F4D;&#x6570;&#xFF1A;<br>$${{\tilde r}_{jm}} = media{n_{{{\bf{x}}_i} \in {R_{jm}}}}\left\{ {{r_{m - 1}}\left( {{{\bf{x}}_i}} \right)} \right\}$$<br>&#x5176;&#x4E2D;${r_{m - 1}}\left( {{{\bf{x}}_i}} \right) = {y_i} - {F_{m - 1}}\left( {{{\bf{x}}_i}} \right)$&#x3002;&#x8FD1;&#x4F3C;&#x65B9;&#x6CD5;&#x5982;&#x4E0B;&#xFF1A;<br>$${\gamma _{jm}} = {{\tilde r}_{jm}} + {1 \over {{N_{jm}}}}\sum\limits_{{{\bf{x}}_i} \in {R_{jm}}}^{} {{\mathop{\rm sign}\nolimits} \left( {{r_{m - 1}}\left( {{{\bf{x}}_i}} \right) - {{\tilde r}_{jm}}} \right)}  \cdot \min \left( {{\delta _m},abs\left( {{r_{m - 1}}\left( {{{\bf{x}}_i}} \right) - {{\tilde r}_{jm}}} \right)} \right)$$<br>&#x5176;&#x4E2D;&#xFF0C;$N_{jm}$&#x4E3A;&#x7B2C;$j$&#x8282;&#x70B9;&#x4E0A;&#x89C2;&#x6D4B;&#x503C;&#x603B;&#x6570;&#x3002;&#x6709;&#x4E86;$\gamma_{jm}$&#x6211;&#x4EEC;&#x53EF;&#x4EE5;&#x6839;&#x636E;GBDT&#x6846;&#x67B6;&#x5199;&#x51FA;&#x6D41;&#x7A0B;&#xFF1A;<br>$$\eqalign{
  &amp; {F_0}\left( {\bf{x}} \right) = median\left\{ {{y_i}} \right\}_1^N  \cr 
  &amp; For\;m = 1\;to\;M\;do:  \cr 
  &amp; \;\;\;\;{r_{m - 1}}\left( {{{\bf{x}}_i}} \right) = {y_i} - {F_{m - 1}}\left( {{{\bf{x}}_i}} \right),i = 1,N  \cr 
  &amp; \;\;\;\;{\delta _m} = quantil{e_\alpha }\left\{ {\left| {{r_{m - 1}}\left( {{{\bf{x}}_i}} \right)} \right|} \right\}_1^N  \cr 
  &amp; \;\;\;\;{{\tilde y}_i} = \left\{ {\matrix{
   {{r_{m - 1}}\left( {{{\bf{x}}_i}} \right),\;\;\;\;\left| {{r_{m - 1}}\left( {{{\bf{x}}_i}} \right)} \right| \le {\delta _m}}  \cr 
   {{\delta _m} \cdot {\mathop{\rm sign}\nolimits} \left( {{r_{m - 1}}\left( {{{\bf{x}}_i}} \right)} \right),\left| {{r_{m - 1}}\left( {{{\bf{x}}_i}} \right)} \right| &gt; {\delta _m}}  \cr 
 } } \right.,i = 1,N  \cr 
  &amp; \;\;\;\;\left\{ {{R_{jm}}} \right\}_1^J = J - node\;tree\left( {\left\{ {{{\tilde y}_i},{{\bf{x}}_i}} \right\}_1^N} \right)  \cr 
  &amp; \;\;\;\;{{\tilde r}_{jm}} = media{n_{{{\bf{x}}_i} \in {R_{jm}}}}\left\{ {{r_{m - 1}}\left( {{{\bf{x}}_i}} \right)} \right\},j = 1,J  \cr 
  &amp; \;\;\;\;{\gamma _{jm}} = {{\tilde r}_{jm}} + {1 \over {{N_{jm}}}}\sum\limits_{}^{} {{\mathop{\rm sign}\nolimits} \left( {{r_{m - 1}}\left( {{x_i}} \right) - {{\tilde r}_{jm}}} \right) \cdot \min \left( {{\delta _m},abs\left( {{r_{m - 1}}\left( {{x_i}} \right) - {{\tilde r}_{jm}}} \right)} \right)}   \cr 
  &amp; \;\;\;\;\;\;\;\;j = 1,N  \cr 
  &amp; \;\;\;\;{F_m}\left( {\bf{x}} \right) = {F_{m - 1}}\left( {\bf{x}} \right) + \sum\limits_{j = 1}^J {{\gamma _{jm}}1\left( {{\bf{x}} \in {R_{jm}}} \right)}   \cr 
  &amp; endFor \cr} $$<br>  &#x4E0B;&#x56FE;&#x7ED8;&#x5236;&#x4E86;LS&#x3001;LAD&#x3001;huber&#x7684;LOSS&#x66F2;&#x7EBF;&#xFF0C;&#x53EF;&#x4EE5;&#x770B;&#x5230;&#x4EE5;$\delta$&#x4E3A;&#x5206;&#x754C;&#x70B9;&#xFF0C;&#x4E2D;&#x95F4;&#x5448;&#x73B0;LS&#x7684;&#x6027;&#x8D28;&#xFF0C;&#x4E24;&#x8FB9;&#x5448;&#x73B0;LAD&#x7684;&#x7EBF;&#x6027;&#x3002;<br>  <img src="/2016/10/02/gradient-boosting-decision-tree-2/./1475380493153.png" alt="loss function curve"></p>
<p>&#x4E0B;&#x9762;&#x4ECB;&#x7ECD;GBDT&#x7528;&#x4E8E;&#x5206;&#x7C7B;&#x95EE;&#x9898;&#xFF1A;</p>
<h4 id="GBDT&#x7528;&#x4E8E;&#x4E8C;&#x5206;&#x7C7B;"><a href="#GBDT&#x7528;&#x4E8E;&#x4E8C;&#x5206;&#x7C7B;" class="headerlink" title="GBDT&#x7528;&#x4E8E;&#x4E8C;&#x5206;&#x7C7B;"></a><strong>GBDT&#x7528;&#x4E8E;&#x4E8C;&#x5206;&#x7C7B;</strong></h4><p>&#x5982;&#x4F55;&#x7528;GB&#x65B9;&#x5F0F;&#x89E3;&#x51B3;&#x4E8C;&#x5206;&#x7C7B;&#x95EE;&#x9898;&#x3002;&#x6211;&#x4EEC;&#x9996;&#x5148;&#x5B9A;&#x4E49;<em>loss function</em>&#x4E3A;&#x8D1F;&#x4E8C;&#x5143;log&#x4F3C;&#x7136;&#x51FD;&#x6570;(negative binomial log-liklihood)&#xFF1A;<br>$$L(y,F)=log(1+exp(-2yF)), y \in \{-1, 1\}$$<br>&#x5176;&#x4E2D;$$F\left( {\bf{x}} \right) = {1 \over 2}\log \left[ {{{\Pr \left( {y = 1|{\bf{x}}} \right)} \over {\Pr \left( {y =  - 1|{\bf{x}}} \right)}}} \right]--(3)$$<br>&#x6709;&#x4E86;<em>loss function</em>&#x53EF;&#x4EE5;&#x8FDB;&#x4E00;&#x6B65;&#x5F97;&#x5230;_pseudo<em>responce</em><br>$${y_i} =  - {\left[ {{{\partial L\left( {{y_i},F\left( {{{\bf{x}}_i}} \right)} \right)} \over {\partial F\left( {{{\bf{x}}_i}} \right)}}} \right]_{F\left( {\bf{x}} \right) = {F_{m - 1}}\left( {\bf{x}} \right)}} = {{2{y_i}} \over {1 + \exp \left( {2{y_i}{F_{m - 1}}\left( {{{\bf{x}}_i}} \right)} \right)}}$$<br>&#x6B65;&#x957F;&#x901A;&#x8FC7;&#x7EBF;&#x641C;&#x7D22;&#x5F97;&#x5230;&#xFF1A;<br>$${\rho _m} = \arg \mathop {\min }\limits_\rho  \sum\limits_{i = 1}^N {\log \left( {1 + \exp \left( { - 2{y_i}\left( {{F_{m - 1}}\left( {{{\bf{x}}_i}} \right) + \rho h\left( {{{\bf{x}}_i};{{\bf{a}}_m}} \right)} \right)} \right)} \right)} $$<br>&#x5BF9;&#x4E8E;GBDT&#xFF0C;&#x6211;&#x4EEC;&#x7528;&#x6811;&#x6A21;&#x578B;&#x4F5C;&#x4E3A;${h\left( {{{\bf{x}}_i};{{\bf{a}}_m}} \right)}$&#x3002;&#x548C;&#x56DE;&#x5F52;&#x95EE;&#x9898;&#x7684;&#x5904;&#x7406;&#x7C7B;&#x4F3C;&#xFF0C;&#x6211;&#x4EEC;&#x53EF;&#x4EE5;&#x5F97;&#x5230;&#x6BCF;&#x4E2A;&#x8282;&#x70B9;$R_{jm}$&#x4E0A;&#x7684;&#x66F4;&#x65B0;&#x89C4;&#x5219;&#xFF1A;<br>$${\gamma _{jm}} = \arg \mathop {\min }\limits_\gamma  \sum\limits_{{{\bf{x}}_i} \in {R_{jm}}}^{} {\log \left( {1 + \exp \left( { - 2{y_i}\left( {{F_{m - 1}}\left( {{{\bf{x}}_i}} \right) + \gamma } \right)} \right)} \right)} -- (4)$$<br>&#x516C;&#x5F0F;$(4)$&#x6CA1;&#x6709;&#x95ED;&#x5F0F;&#x89E3;&#xFF0C;&#x6211;&#x4EEC;&#x901A;&#x8FC7;&#x5355;&#x6B65;&#x62DF;&#x725B;&#x987F;&#x6CD5;&#x8FDB;&#x884C;&#x8FD1;&#x4F3C;&#xFF1A;<br>$${\gamma _{jm}} = \sum\limits_{{{\bf{x}}_i} \in {R_{jm}}} {{{{{\tilde y}_i}} \over {\sum\limits_{{{\bf{x}}_i} \in {R_{jm}}} {\left| {{{\tilde y}_i}} \right|\left( {2 - \left| {{{\tilde y}_i}} \right|} \right)} }}} $$<br>&#x8FD9;&#x91CC;&#x7684;${\tilde y}_i$&#x4E3A;<em>pseudo-response</em>&#x3002;&#x7B97;&#x6CD5;&#x6D41;&#x7A0B;&#x4E3A;&#xFF1A;<br>$$\eqalign{
  &amp; {F_0}\left( {\bf{x}} \right) = {1 \over 2}\log {{1 + \bar y} \over {1 - \bar y}}  \cr 
  &amp; For\;m = 1\;to\;M\;do:  \cr 
  &amp; \;\;\;\;{{\tilde y}_i} = {{2{y_i}} \over {1 + \exp \left( {2{y_i}{F_{m - 1}}\left( {{{\bf{x}}_i}} \right)} \right)}},i = 1,N  \cr 
  &amp; \;\;\;\;\left\{ {{R_{jm}}} \right\}_1^J = J - tree\left( {\left\{ {{{\tilde y}_i},{{\bf{x}}_i}} \right\}_1^N} \right)  \cr 
  &amp; \;\;\;\;{\gamma _{jm}} = \sum\limits_{{{\bf{x}}_i} \in {R_{jm}}}^{} {{{{{\tilde y}_i}} \over {\sum\limits_{{{\bf{x}}_i} \in {R_{jm}}} {\left| {{{\tilde y}_i}} \right|\left( {2 - \left| {{{\tilde y}_i}} \right|} \right)} }}} ,j = 1,J  \cr 
  &amp; \;\;\;\;{F_m}\left( {\bf{x}} \right) = {F_{m - 1}}\left( {\bf{x}} \right) + \sum\limits_{j = 1}^J {{\gamma _{jm}}1\left( {{\bf{x}} \in {R_{jm}}} \right)}   \cr 
  &amp; end\;For \cr} $$<br>  &#x5F97;&#x5230;&#x6700;&#x7EC8;&#x7684;$F_m({\bf x})$&#x4E3A;$F({\bf x})$&#x7684;&#x8FD1;&#x4F3C;&#xFF0C;$F({\bf x})$&#x4E3A;&#xFF1A;<br>  $$F\left( {\bf{x}} \right) = {1 \over 2}\log \left[ {{{\Pr \left( {y = 1|{\bf{x}}} \right)} \over {\Pr \left( {y =  - 1|{\bf{x}}} \right)}}} \right]--(3)$$<br>  &#x6765;&#x4E86;&#x4E00;&#x4E2A;&#x65B0;&#x6837;&#x672C;$x_j$&#xFF0C;&#x82E5;$F_m({x_j})&gt;0$&#xFF0C;&#x5219;$y=1$&#xFF0C;&#x53CD;&#x4E4B;&#x5219;$y=-1$&#x3002;<br>  &#x6839;&#x636E;$(3)$&#x5F0F;&#xFF0C;&#x6211;&#x4EEC;&#x53EF;&#x4EE5;&#x8BA1;&#x7B97;&#x5F97;&#x5230;&#x5206;&#x5C5E;&#x4E0D;&#x540C;&#x7C7B;&#x522B;&#x7684;&#x6982;&#x7387;&#xFF1A;<br>  $${p_ + }\left( {\bf{x}} \right) = \tilde Pr\left( {y = 1|{\bf{x}}} \right) = {1 \over {1 + \exp \left( { - 2{F_M}\left( {\bf{x}} \right)} \right)}}$$<br> $${p_ - }\left( {\bf{x}} \right) = \tilde Pr\left( {y =  - 1|{\bf{x}}} \right) = {1 \over {1 + \exp \left( {2{F_M}\left( {\bf{x}} \right)} \right)}}$$<br> &#x53EF;&#x4EE5;&#x6839;&#x636E;&#x4E0D;&#x540C;&#x7684;&#x5E94;&#x7528;&#xFF0C;&#x8FDB;&#x884C;&#x8C03;&#x6743;&#xFF1A;<br> $$\tilde y\left( {\bf{x}} \right) = 2 \cdot 1\left( {c\left( { - 1,1} \right){p_ + }\left( {\bf{x}} \right) &gt; c\left( {1, - 1} \right){p_ - }\left( {\bf{x}} \right)} \right) - 1$$<br> &#x5176;&#x4E2D;${c\left( {\tilde y, y} \right)}$&#x4E3A;&#x5C06;$y$&#x8BC6;&#x522B;&#x6210;$\tilde y$&#x7684;cost&#x3002;<br> <strong>&#x526A;&#x679D;</strong><br>GB&#x6846;&#x67B6;&#x89E3;&#x51B3;&#x4E8C;&#x5206;&#x7C7B;&#x95EE;&#x9898;&#x7684;<em>loss function</em>&#x5728;&#x7B2C;m&#x8F6E;&#x8FED;&#x4EE3;&#x4E2D;&#x5982;&#x4E0B;&#xFF1A;<br> $${\phi _m}\left( {\rho ,{\bf{a}}} \right) = \sum\limits_{i = 1}^N {\log \left[ {1 + \exp \left( { - 2{y_i}{F_{m - 1}}\left( {{{\bf{x}}_i}} \right)} \right) \cdot \exp \left( { - 2{y_i}\rho h\left( {{{\bf{x}}_i};{\bf{a}}} \right)} \right)} \right]} $$<br> &#x968F;&#x7740;&#x8FED;&#x4EE3;&#x7EE7;&#x7EED;&#xFF0C;${{y_i}{F_{m - 1}}\left( {{{\bf{x}}_i}} \right)}$&#x4F1A;&#x53D8;&#x6210;&#x5F88;&#x5927;&#xFF0C;&#x4F7F;&#x5F97;&#x7ED3;&#x679C;&#x4E0D;&#x518D;&#x53D7;&#x65B0;&#x7684;&#x6837;&#x672C;&#x5F71;&#x54CD;&#x3002;&#x4E5F;&#x5C31;&#x662F;&#x8BF4;&#xFF0C;&#x5F53;${{y_i}{F_{m - 1}}\left( {{{\bf{x}}_i}} \right)}$&#x5F88;&#x5927;&#xFF0C;$ \exp \left( { - 2{y_i}{F_{m - 1}}\left( {{{\bf{x}}_i}} \right)} \right)$&#x4F1A;&#x76F8;&#x5BF9;&#x5F88;&#x5C0F;&#x3002;<br>&#x89C6;&#x5176;&#x4E3A;&#x6743;&#x91CD;${w_i} = \exp \left( { - 2{y_i}{F_{m - 1}}\left( {{{\bf{x}}_i}} \right)} \right)$&#xFF0C;&#x4F5C;&#x4E3A;&#x7B2C;$i$&#x4E2A;&#x6570;&#x636E;&#x7684;&#x5F71;&#x54CD;&#x529B;&#x3002;<br>&#x526A;&#x679D;&#x7684;&#x505A;&#x6CD5;&#x662F;&#x5C06;&#x6743;&#x91CD;$w_i \le w_{l(\alpha)}$&#xFF0C;&#x5176;&#x4E2D;$l(\alpha)$&#x4E3A;&#x4E0B;&#x5F0F;&#x7684;&#x89E3;&#xFF1A;<br>$$\sum\limits_{i = 1}^{l\left( \alpha  \right)} {{w_{\left( i \right)}}}  = \alpha \sum\limits_{i = 1}^N {{w_i}} $$<br>&#x901A;&#x5E38;$\alpha \in [0.05, 0.2]$&#xFF0C;&#x8FD9;&#x91CC;&#x7684;&#x526A;&#x679D;&#x548C;AdaBoost&#x7684;&#x201D;weight trimming&#x201D;&#x662F;&#x4E00;&#x6837;&#x7684;&#x3002;&#x5C06;&#x8FD1;90%&#x5230;95%&#x7684;&#x6837;&#x672C;&#x5019;&#x9009;&#x88AB;&#x526A;&#x679D;&#xFF0C;&#x5E26;&#x6765;10%&#x5230;20%&#x7684;&#x8BA1;&#x7B97;&#x901F;&#x5EA6;&#x63D0;&#x5347;&#x3002;&#x4E0B;&#x9762;&#x4ECB;&#x7ECD;GBDT&#x7528;&#x4E8E;&#x591A;&#x5206;&#x7C7B;&#x95EE;&#x9898;&#x3002;</p>
<h4 id="GBDT&#x7528;&#x4E8E;&#x591A;&#x5206;&#x7C7B;"><a href="#GBDT&#x7528;&#x4E8E;&#x591A;&#x5206;&#x7C7B;" class="headerlink" title="GBDT&#x7528;&#x4E8E;&#x591A;&#x5206;&#x7C7B;"></a><strong>GBDT&#x7528;&#x4E8E;&#x591A;&#x5206;&#x7C7B;</strong></h4><p>&#x5BF9;&#x4E8E; $K$-&#x7C7B;&#x95EE;&#x9898;&#xFF0C;&#x540C;&#x6837;&#x5B9A;&#x4E49;<em>loss function</em>&#x662F;<br>$$L\left( {\left\{ {{y_k},{F_k}\left( {\bf{x}} \right)} \right\}_1^K} \right) =  - \sum\limits_{k = 1}^K {{y_k}\log {p_k}\left( {\bf{x}} \right)}--(4) $$<br>&#x5176;&#x4E2D;&#xFF0C;$y_k=1(class=k) \in \{0, 1\}$&#xFF0C;$p_k({\bf x})=Pr(y_k=1|{\bf x})$&#xFF0C;<br>$${p_k}\left( {\bf{x}} \right) = {{\exp \left( {{F_k}\left( {\bf{x}} \right)} \right)} \over {\sum\limits_{l = 1}^K {\exp \left( {{F_k}\left( {\bf{x}} \right)} \right)} }} -- (5)$$<br>$${F_k}\left( {\bf{x}} \right) = \log {p_k}\left( {\bf{x}} \right) - {1 \over K}\sum\limits_{l = 1}^K {\log {p_l}\left( {\bf{x}} \right)} --(6)$$<br>$(5)$&#x3001;$(6)$&#x662F;&#x7B49;&#x4EF7;&#x3002;<br>&#x5C06;$(6)$&#x5E26;&#x5165;&#x5230;$(4)$&#xFF0C;&#x6C42;&#x4E00;&#x9636;&#x5BFC;&#x53EF;&#x5F97;&#xFF1A;<br>$${{\tilde y}_{ik}} =  - {\left[ {{{\partial L\left( {\left\{ {{y_{il}},{F_l}\left( {{{\bf{x}}_i}} \right)} \right\}_{l = 1}^K} \right)} \over {\partial {F_k}\left( {{{\bf{x}}_i}} \right)}}} \right]_{\left\{ {{F_l}\left( {\bf{x}} \right) = {F_{l,m - 1}}\left( {\bf{x}} \right)} \right\}_1^K}} = {y_{ik}} - {p_{k,m - 1}}\left( {{{\bf{x}}_i}} \right)$$<br>&#x5176;&#x4E2D;&#xFF0C;$p_{k,m-1}$&#x4ECE;$F_{k,m-1}(x)$&#x7684;&#x51FD;&#x6570;$(5)$&#x5BFC;&#x51FA;&#x3002;&#x7B2C;$m$&#x8F6E;&#x7528;K&#x68F5;trees&#x9884;&#x6D4B;&#x5BF9;&#x5E94;&#x6BCF;&#x7C7B;&#x7684;&#x6B8B;&#x5DEE;&#xFF0C;&#x6BCF;&#x68F5;&#x6811;&#x6709;$J$&#x4E2A;&#x8282;&#x70B9;&#xFF0C;&#x8BB0;&#x4F5C;$\{R_{jkm}\}^J_{j=1}$&#x3002;&#x6A21;&#x578B;&#x7684;&#x53C2;&#x6570;$\gamma _{jkm}$&#x66F4;&#x65B0;&#x89C4;&#x5219;&#xFF1A;<br>$$\left\{ {{\gamma _{jkm}}} \right\} = \arg \mathop {\min }\limits_{\left\{ {{\gamma _{jk}}} \right\}} \sum\limits_{i = 1}^N {\sum\limits_{k = 1}^N {\phi \left( {{y_{ik}},{F_{k,m - 1}}\left( {{{\bf{x}}_i}} \right) + \sum\limits_{j = 1}^J {{\gamma _{jk}}1\left( {{{\bf{x}}_i} \in {R_{jm}}} \right)} } \right)} } (7)$$<br>&#x5176;&#x4E2D;&#xFF0C;$\phi \left( {{y_k},{F_k}} \right) =  - {y_k}\log {p_k}$&#xFF0C;${F_k}\left( {\bf{x}} \right) = \log {p_k}\left( {\bf{x}} \right) - {1 \over K}\sum\limits_{l = 1}^K {\log {p_l}\left( {\bf{x}} \right)} $&#x3002;$(7)$&#x65E0;&#x95ED;&#x5F0F;&#x89E3;&#xFF0C;&#x53EF;&#x4EE5;&#x901A;&#x8FC7;&#x5355;&#x6B65;Newton-Raphson&#x4F7F;&#x7528;&#x4E00;&#x4E2A;&#x5BF9;&#x89D2;&#x77E9;&#x9635;&#x8FD1;&#x4F3C;Hessian&#x77E9;&#x9635;&#x3002;<br>$${\gamma _{jkm}} = {{K - 1} \over K}{{\sum\limits_{{{\bf{x}}_i} \in {R_{jkm}}}^{} {{{\tilde y}_{ik}}} } \over {\sum\limits_{{{\bf{x}}_i} \in {R_{jkm}}}^{} {\left| {{{\tilde y}_{ik}}} \right|\left( {1 - \left| {{{\tilde y}_{ik}}} \right|} \right)} }}$$<br>&#x8FD9;&#x6837;&#x6211;&#x4EEC;&#x53EF;&#x4EE5;&#x6784;&#x5EFA;&#x51FA;$K$&#x7C7B;&#x522B;&#x7684;logistic GBDT&#x6846;&#x67B6;&#x5982;&#x4E0B;&#xFF1A;<br>$$\eqalign{
  &amp; {F_{k0}}\left( {\bf{x}} \right) = 0,k = 1,K  \cr 
  &amp; For\;m = 1\;to\;M\;do:  \cr 
  &amp; \;\;\;\;{p_k}\left( {\bf{x}} \right) = {{\exp \left( {{F_k}\left( {\bf{x}} \right)} \right)} \over {\sum\limits_{l = 1}^K {\exp \left( {{F_l}\left( {\bf{x}} \right)} \right)} }},k = 1,K  \cr 
  &amp; \;\;\;\;For\;k = 1\;to\;K\;do:  \cr 
  &amp; \;\;\;\;\left\{ {{R_{jkm}}} \right\}_{j = 1}^J = J - tree\left( {\left\{ {{{\tilde y}_{ik}},{{\bf{x}}_i}} \right\}_1^N} \right)  \cr 
  &amp; \;\;\;\;{\gamma _{jkm}} = {{K - 1} \over K}{{\sum\limits_{{x_i} \in {R_{jkm}}} {{{\tilde y}_{ik}}} } \over {\sum\limits_{{{\bf{x}}_i} \in {R_{jkm}}} {\left| {{{\tilde y}_{ik}}} \right|\left( {1 - \left| {{{\tilde y}_{ik}}} \right|} \right)} }},j = 1,J  \cr 
  &amp; \;\;\;\;{F_{km}}\left( {\bf{x}} \right) = {F_{k,m - 1}}\left( {\bf{x}} \right) + \sum\limits_{j = 1}^J {{\gamma _{jkm}}1\left( {{\bf{x}} \in {R_{jkm}}} \right)}   \cr 
  &amp; \;\;\;\;endFor  \cr 
  &amp; endFor \cr} $$<br>&#x9884;&#x6D4B;&#x548C;&#x4E8C;&#x5206;&#x7C7B;&#x95EE;&#x9898;&#x7C7B;&#x4F3C;&#xFF0C;&#x6211;&#x4EEC;&#x5F97;&#x5230;$\left\{ {{F_{km}}\left( {\bf{x}} \right)} \right\}_1^K$&#x53EF;&#x4EE5;&#x7528;&#x4E8E;&#x9884;&#x4F30;$\left\{ {{p_{km}}\left( {\bf{x}} \right)} \right\}_1^K$&#x3002;&#x7C7B;&#x522B;&#x9884;&#x6D4B;&#x7ED3;&#x679C;&#x4E3A;&#xFF1A;$${\hat k}\left( {\bf{x}} \right) = \arg \mathop {\min }\limits_{1 \le k \le K} \sum\limits_{k&apos; = 1}^K {c\left( {k,k&apos;} \right)} {p_{k&apos;M}}\left( {\bf{x}} \right)$$<br>$c(k,k&apos;)$&#x8868;&#x793A;&#x771F;&#x5B9E;label($k&apos;$)&#x9884;&#x6D4B;&#x4E3A;predict($k$)&#x7684;cost&#x3002;</p>
<blockquote>
<p>&#x5BF9;&#x4E8E;$p_{k&apos;M}\left( {\bf{x}} \right)$&#x4E3A;&#x6837;&#x672C;$\bf x$&#x9884;&#x6D4B;&#x4E3A;$k$&#x7C7B;&#x7684;&#x6982;&#x7387;&#x3002;&#x800C;${\hat k}(x)$&#x7684;$argmin$&#x4E0D;&#x592A;&#x597D;&#x7406;&#x89E3;&#x3002;&#x5982;&#x679C;&#x662F;&#x6C42;&#x6700;&#x7EC8;cost&#x7684;&#x8BDD;&#xFF0C;&#x80FD;&#x7406;&#x89E3;&#x3002;&#x4F46;&#x662F;&#x5BF9;&#x4E8E;&#x524D;&#x9762;&#x4ECB;&#x7ECD;&#x8FC7;&#x7684;&#x4E8C;&#x5206;&#x7C7B;&#x6807;&#x7B7E;&#x7684;&#x5224;&#x65AD;&#x516C;&#x5F0F;&#xFF0C;&#x4F3C;&#x4E4E;&#x6709;&#x96BE;&#x901A;&#x987A;&#x7684;&#x5730;&#x65B9;&#xFF0C;&#x662F;&#x4E0D;&#x662F;&#x8FD9;&#x91CC;&#x7684;&#x6BD4;&#x8F83;&#x90E8;&#x5206;&#x5E94;&#x8BE5;&#x662F;&#x5C0F;&#x4E8E;&#x53F7;$<$？：<br>$$\tilde y\left( {\bf{x}} \right) = 2 \cdot 1\left( {c\left( { - 1,1} \right){p_ + }\left( {\bf{x}} \right) &gt; c\left( {1, - 1} \right){p_ - }\left( {\bf{x}} \right)} \right) - 1$$</$？：<br></p>
</blockquote>
<ol>
<li>&#x601D;&#x8003;&#xFF1A;&#x6700;&#x5C0F;&#x7EDD;&#x5BF9;&#x503C;&#x504F;&#x5DEE;&#x7684;&#x5BFC;&#x6570;&#x4E3A;&#x4EC0;&#x4E48;&#x662F;sign(y-F)  &#x4E0B;&#x9762;&#x56FE;&#x4E3A;|1-x|&#x7684;&#x66F2;&#x7EBF;&#xFF0C;&#x5BFC;&#x6570;&#x4E3A;&#x5206;&#x6BB5;&#x51FD;&#x6570;&#xFF0C;&#x503C;&#x57DF;&#x4E3A;{-1,+1}</li>
</ol>
<p><img src="/2016/10/02/gradient-boosting-decision-tree-2/./1473923878477.png" alt="Alt text"></p>
<ol>
<li>&#x601D;&#x8003;&#xFF1A;LAD (least absolut deviation)&#x7684;&#x62DF;&#x5408;H(x;a, $\rho$)&#x4E2D;$\rho$&#x4E3A;&#x4F55;&#x662F;&#x4E2D;&#x4F4D;&#x6570;&#x3002;<br>H(X; a)&#x4E3A;&#x7B26;&#x53F7;&#x51FD;&#x6570;&#xFF0C;&#x800C;&#x5BF9;&#x4E8E;$\sum\nolimits_i {\left| {{y_i} - \rho } \right|} $&#xFF0C;&#x6700;&#x4F18;&#x89E3;&#x4E3A;$median_y$</li>
<li>&#x601D;&#x8003;&#xFF1A; &#x6700;&#x5C0F;&#x7EDD;&#x5BF9;&#x8BEF;&#x5DEE;&#x7684;&#x5747;&#x503C;&#x6BD4;LAD&#x91CC;&#x504F;&#x5DEE;&#x7684;&#x4E2D;&#x4F4D;&#x6570;&#x66F4;&#x5BB9;&#x6613;&#x8BA1;&#x7B97;&#x3002;LAD&#x91CC;&#x504F;&#x5DEE;&#x7684;&#x4E2D;&#x4F4D;&#x6570;&#x66F4;&#x9C81;&#x68D2;&#x3002;</li>
<li>&#x601D;&#x8003;&#xFF1A;M-regression[huber]&#x7684;$\alpha$&#x5206;&#x4F4D;&#x6570;&#x662F;&#x4EC0;&#x4E48;&#x6982;&#x5FF5;<br> &#x731C;&#x60F3;&#x914D;&#x5408;&#x524D;&#x9762;<em>loss function</em>&#x5B9A;&#x4E49;&#x8FD9;&#x91CC;&#x5E94;&#x8BE5;&#x662F;&#x7528;&#x7684;&#x53CC;&#x4FA7;&#x5206;&#x4F4D;&#x6570;&#x3002;$\alpha$-&#x53CC;&#x4FA7;&#x5206;&#x4F4D;&#x6570;&#x7684;&#x5B9A;&#x4E49;&#xFF1A;&#x5F53;&#x968F;&#x673A;&#x53D8;&#x91CF;$X$&#x7684;&#x5206;&#x5E03;&#x51FD;&#x6570;&#x4E3A; $F(x)$&#xFF0C;$0 \lt \alpha \lt 1$&#xFF0C;$\alpha$&#x5206;&#x4F4D;&#x6570;&#x662F;&#x4F7F;$P\{X \lt \delta\}=F(X)=0.5\alpha$ &amp;$P\{X &gt; \delta\}=F(X)=0.5\alpha$&#x3002;&#x5047;&#x5B9A;&#x6211;&#x4EEC;&#x4EE4;$\alpha=0.2$&#xFF0C;&#x90A3;&#x4E48;&#x6211;&#x4EEC;&#x5C06;&#x5BF9;$\delta$&#x6EE1;&#x8DB3;$P\{X \lt \delta\}<0.1$&amp;$p\{x> \delta\}<0.1$的样本使用 <em="">loss function $\delta(|y-F|-\delta/2)$&#x3002;&#x5176;&#x4F59;&#x6837;&#x672C;&#x4F7F;&#x7528;LS loss&#x3002;&#x8FD8;&#x9700;&#x8981;&#x8FDB;&#x4E00;&#x6B65;&#x786E;&#x8BA4;</0.1$的样本使用></0.1$&amp;$p\{x></li>
<li>&#x601D;&#x8003;&#xFF1A;GBDT&#x548C;ADAboost&#x4EC0;&#x4E48;&#x5173;&#x7CFB;&#xFF1A;&#x53C2;&#x770B;&#x5F15;&#x6587;[1]&#x7B2C;14&#x9875;</li>
<li>&#x6B63;&#x5219;&#x5316;&#xFF0C;&#x5728;&#x6BCF;&#x6B21;&#x8FED;&#x4EE3;&#x8FC7;&#x7A0B;&#x4E2D;&#x589E;&#x52A0;&#x4E00;&#x4E2A;&#x5B66;&#x4E60;&#x7387;&#x53C2;&#x6570;&#xFF1A;$${F_m}\left( {\bf{x}} \right) = {F_{m - 1}}\left( {\bf{x}} \right) + v \cdot {\rho _m}h\left( {{\bf{x}};{{\bf{a}}_m}} \right),\;\;0 &lt; v \le 1$$</li>
</ol>
<p>[1] Friedman J H. Greedy Function Approximation: A Gradient Boosting Machine[J]. Annals of Statistics, 2000, 29(5):1189&#x2013;1232.<br>[2]Huber, P. (1964). Robust estimation ofa location parameter. Ann. Math. Statist. 35 73&#x2013;101.<br>[3]Friedman J, Tibshirani R. Special Invited Paper. Additive Logistic Regression: A Statistical View of Boosting: Discussion[J]. Annals of Statistics, 2000, 28(2):pages. 374-376.</p>
</div><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a data-url="https://qiugen.github.io/2016/10/02/gradient-boosting-decision-tree-2/" data-id="ciu44xisk000c5klpn6k5d7kt" class="article-share-link">分享到</a><div class="tags"><a href="/tags/gbdt/">gbdt</a><a href="/tags/gradient-boosting-framework/">gradient boosting framework</a><a href="/tags/huber/">huber</a><a href="/tags/LST/">LST</a><a href="/tags/LAD/">LAD</a><a href="/tags/classify/">classify</a></div><div class="post-nav"><a href="/2016/10/05/a-guide-to-xgboost-A-Scalable-Tree-Boosting-System/" class="pre">xgboost: A Scalable Tree Boosting System论文及源码导读</a><a href="/2016/09/24/gradient-boosting-decision-tree-1/" class="next">gradient boosting decision tree[上篇]</a></div><div data-thread-key="2016/10/02/gradient-boosting-decision-tree-2/" data-title="gradient boosting decision tree[下篇]" data-url="https://qiugen.github.io/2016/10/02/gradient-boosting-decision-tree-2/" class="ds-share flat"><div class="ds-share-inline"><ul class="ds-share-icons-16"><li data-toggle="ds-share-icons-more"><a href="javascript:void(0);" class="ds-more">分享到：</a></li><li><a href="javascript:void(0);" data-service="weibo" class="ds-weibo">微博</a></li><li><a href="javascript:void(0);" data-service="qzone" class="ds-qzone">QQ空间</a></li><li><a href="javascript:void(0);" data-service="qqt" class="ds-qqt">腾讯微博</a></li><li><a href="javascript:void(0);" data-service="wechat" class="ds-wechat">微信</a></li></ul><div class="ds-share-icons-more"></div></div></div><div data-thread-key="2016/10/02/gradient-boosting-decision-tree-2/" data-title="gradient boosting decision tree[下篇]" data-url="https://qiugen.github.io/2016/10/02/gradient-boosting-decision-tree-2/" data-author-key="1" class="ds-thread"></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form action="//www.baidu.com/baidu" method="get" accept-charset="utf-8" target="_blank" class="search-form"><input type="search" name="word" maxlength="20" placeholder="Search"/><input type="hidden" name="si" value="https://qiugen.github.io"/><input name="tn" type="hidden" value="bds"/><input name="cl" type="hidden" value="3"/><input name="ct" type="hidden" value="2097152"/><input name="s" type="hidden" value="on"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/其他/">其他</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/">机器学习</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/logisticRank/" style="font-size: 15px;">logisticRank</a> <a href="/tags/user-targeting/" style="font-size: 15px;">user targeting</a> <a href="/tags/learning-to-rank/" style="font-size: 15px;">learning to rank</a> <a href="/tags/query-rewriting/" style="font-size: 15px;">query rewriting</a> <a href="/tags/semantic-matching/" style="font-size: 15px;">semantic matching</a> <a href="/tags/deep-learning/" style="font-size: 15px;">deep learning</a> <a href="/tags/RBMs/" style="font-size: 15px;">RBMs</a> <a href="/tags/xgboost/" style="font-size: 15px;">xgboost</a> <a href="/tags/gbdt/" style="font-size: 15px;">gbdt</a> <a href="/tags/gbRank/" style="font-size: 15px;">gbRank</a> <a href="/tags/advertisement/" style="font-size: 15px;">advertisement</a> <a href="/tags/gradient-boosting-framework/" style="font-size: 15px;">gradient boosting framework</a> <a href="/tags/huber/" style="font-size: 15px;">huber</a> <a href="/tags/LST/" style="font-size: 15px;">LST</a> <a href="/tags/LAD/" style="font-size: 15px;">LAD</a> <a href="/tags/classify/" style="font-size: 15px;">classify</a> <a href="/tags/model/" style="font-size: 15px;">model</a> <a href="/tags/bayes/" style="font-size: 15px;">bayes</a> <a href="/tags/hexo/" style="font-size: 15px;">hexo</a> <a href="/tags/mathjex-公式/" style="font-size: 15px;">mathjex 公式</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2016/10/05/a-guide-to-xgboost-A-Scalable-Tree-Boosting-System/">xgboost: A Scalable Tree Boosting System论文及源码导读</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/10/02/gradient-boosting-decision-tree-2/">gradient boosting decision tree[下篇]</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/09/24/gradient-boosting-decision-tree-1/">gradient boosting decision tree[上篇]</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/09/18/gbRank-logsitRank-from-up-to-bottom/">gbRank & logsitcRank自顶向下</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/09/13/Ranking-Relevance-in-Yahoo-Search/">[笔记]Ranking Relevance in Yahoo Search</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/09/03/Large-scale-behavioral-user-targeting/">[笔记]Large-scale behavioral user targeting</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/09/03/solved-mathjex-problem/">解决hexo(jekyll) mathjex 插入公式后渲染问题</a></li><li class="post-list-item"><a class="post-list-link" href="/2014/05/11/Training-Products-of-Experts-by-Minimizing-Contrastive-Divergence/">[笔记]Training Products of Experts by Minimizing Contrastive Divergence</a></li><li class="post-list-item"><a class="post-list-link" href="/2014/03/02/naive-bayes-classify/">朴素贝叶斯分类算法简介</a></li><li class="post-list-item"><a class="post-list-link" href="/2013/05/29/徐志摩诗一首/">再休怪我的脸沉</a></li></ul></div><div class="widget"><div class="comments-title"><i class="fa fa-comment-o"> 最近评论</i></div><div data-num-items="5" data-show-avatars="0" data-show-time="1" data-show-admin="0" data-excerpt-length="32" data-show-title="1" class="ds-recent-comments"></div></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://www.example1.com/" title="site-name1" target="_blank">site-name1</a><ul></ul><a href="http://www.example2.com/" title="site-name2" target="_blank">site-name2</a><ul></ul><a href="http://www.example3.com/" title="site-name3" target="_blank">site-name3</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">© <a href="/." rel="nofollow">水滴石穿.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.pack.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="/css/jquery.fancybox.css?v=0.0.0"><script>var duoshuoQuery = {short_name:'qiugen'};
(function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0]
        || document.getElementsByTagName('body')[0]).appendChild(ds);
})();
</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>