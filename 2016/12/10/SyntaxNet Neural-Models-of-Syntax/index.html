<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="enjoy"><title>简介语法分析开源神经网络SyntaxNet | 水滴石穿</title><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/4.2.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/grids-responsive-min.css"><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.0.0/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">简介语法分析开源神经网络SyntaxNet</h1><a id="logo" href="/.">水滴石穿</a><p class="description">探索，保持渴望，无所畏惧</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">简介语法分析开源神经网络SyntaxNet</h1><div class="post-meta">Dec 10, 2016<span> | </span><span class="category"><a href="/categories/机器学习/">机器学习</a></span><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> Hits</span></span></div><a data-thread-key="2016/12/10/SyntaxNet Neural-Models-of-Syntax/" href="/2016/12/10/SyntaxNet Neural-Models-of-Syntax/#comments" class="ds-thread-count"></a><div class="post-content"><p>SyntaxNet&#x5728;github&#x6587;&#x6863;&#x5F00;&#x6E90;&#x90E8;&#x5206;&#x4ECB;&#x7ECD;&#x4E86;&#x4E24;&#x4E2A;&#x6A21;&#x578B;&#xFF1A;&#x8BCD;&#x6027;&#x6807;&#x6CE8;&#x548C;&#x8BED;&#x6CD5;&#x4F9D;&#x5B58;&#x5206;&#x6790;&#xFF0C;&#x8BBA;&#x6587;&#x4E2D;&#x8FD8;&#x6709;&#x53E5;&#x5B50;&#x538B;&#x7F29;&#x90E8;&#x5206;&#x5185;&#x5BB9;&#x3002;[<a href="https://github.com/tensorflow/models/tree/master/syntaxnet#annotating-a-corpus" target="_blank" rel="external">github&#x5730;&#x5740;</a>]&#xFF0C;[<a href="https://github.com/tensorflow/models/tree/master/syntaxnet#annotating-a-corpus" target="_blank" rel="external">&#x76F8;&#x5173;&#x6587;&#x6863;</a>], [<a href="https://arxiv.org/abs/1603.06042" target="_blank" rel="external">&#x5BF9;&#x5E94;&#x8BBA;&#x6587;</a> ]&#x3002;<br>&#x5BF9;&#x5E94;&#x8BBA;&#x6587;&#x4E00;&#x4F5C;&#x4E3A;andor&#xFF0C;&#x9488;&#x5BF9;&#x4E09;&#x4E2A;&#x4EFB;&#x52A1;&#xFF0C;&#x6E10;&#x8FDB;&#x5F0F;&#x4ECB;&#x7ECD;&#x4E86;&#x8BCD;&#x6027;&#x6807;&#x6CE8;(part-of-speech)&#xFF0C;&#x4F9D;&#x5B58;&#x5206;&#x6790;&#xFF0C;&#x53E5;&#x5B50;&#x538B;&#x7F29;&#x4E09;&#x4E2A;&#x90E8;&#x5206;&#x5DE5;&#x4F5C;&#x3002;&#x4F9D;&#x5B58;&#x5206;&#x6790;&#x4F7F;&#x7528;&#x4E86;&#x8BCD;&#x6027;&#x6807;&#x6CE8;&#x7684;&#x8F93;&#x51FA;&#x4F5C;&#x4E3A;&#x8F93;&#x5165;&#x7279;&#x5F81;&#xFF0C;&#x800C;&#x53E5;&#x5B50;&#x538B;&#x7F29;&#x5219;&#x7528;&#x4E86;&#x524D;&#x4E24;&#x4E2A;&#x4EFB;&#x52A1;&#x7684;&#x7ED3;&#x679C;&#x4F5C;&#x4E3A;&#x8F93;&#x5165;&#x7279;&#x5F81;&#x3002; &#x63A5;&#x4E0B;&#x6765;&#x987A;&#x5E8F;&#x4ECB;&#x7ECD;&#x4E0B;&#x4E09;&#x4E2A;&#x5DE5;&#x4F5C;&#xFF1A;</p>
<h4 id="Part-of-Speech-Tagging"><a href="#Part-of-Speech-Tagging" class="headerlink" title="Part-of-Speech Tagging"></a>Part-of-Speech Tagging</h4><p>&#x8BAD;&#x7EC3;&#x65B9;&#x5F0F;&#xFF1A;<br>&#x4ECE;&#x5DE6;&#x5230;&#x53F3;&#x8BAD;&#x7EC3;&#xFF0C;&#x7ED9;&#x5B9A;&#x4E00;&#x4E2A;&#x8BCD;&#xFF0C;&#x62BD;&#x53D6;&#x8BE5;&#x8BCD;&#x548C;&#x7A97;&#x53E3;&#x5185;&#x7684;&#x7279;&#x5F81;&#x4F5C;&#x4E3A;&#x7F51;&#x7EDC;&#x7684;&#x8F93;&#x5165;&#xFF0C;&#x8F93;&#x51FA;&#x4E3A;&#x8BCD;&#x6027;&#x6807;&#x7B7E;&#xFF0C;&#x65E0;&#x5168;&#x5C40;&#x89E3;&#x7801;&#x90E8;&#x5206;&#x3002;<br>&#x5B9E;&#x9A8C;&#x4E2D;&#x7279;&#x5F81;&#x6BD4;&#x8F83;&#x7B80;&#x5355;&#xFF0C;&#x6CA1;&#x6709;&#x7528;&#x590D;&#x6742;&#x7684;&#x4EBA;&#x5DE5;&#x7279;&#x5F81;&#x8BBE;&#x8BA1;&#xFF0C;&#x7279;&#x5F81;&#x8BBE;&#x8BA1;&#x4E3A;&#x5F53;&#x524D;&#x8BCD;&#x7684;$ \pm 3$ &#x4E2A;token&#x7A97;&#x53E3;&#x7684;&#x8BCD;&#xFF0C;&#x7C7B;&#x522B;&#xFF0C;&#x5B57;&#x7B26;&#x7EA7;&#x522B;n-gram(up to length3)&#xFF0C;&#x524D;4&#x4E2A;token&#x7684;&#x9884;&#x6D4B;tag&#x3002;&#x5F97;&#x5230;&#x6240;&#x6709;&#x7279;&#x5F81;&#x62FC;&#x63A5;&#x8D77;&#x6765;&#x4F5C;&#x4E3A;&#x7F51;&#x7EDC;&#x7684;&#x8F93;&#x5165;&#x3002;&#x8F93;&#x51FA;&#x4E3A;&#x5F53;&#x524D;&#x4F4D;&#x7F6E;&#x5404;&#x4E2A;&#x6807;&#x7B7E;&#x7684;&#x5F52;&#x4E00;&#x5316;&#x6982;&#x7387;&#x3002;<br>&#x7F51;&#x7EDC;&#x7ED3;&#x6784;&#x5982;&#x4E0B;&#xFF0C;&#x53C2;&#x8003;[7, cheng, 2014]&#xFF1A;<br><img src="/2016/12/10/SyntaxNet Neural-Models-of-Syntax/./1480572771201.png" alt="&#x56FE;&#x793A;&#xFF1A;&#x524D;&#x9988;SytaxNet&#x7F51;&#x7EDC;&#x7ED3;&#x6784;"><br>Parsey McParseface[1, Daniel Andor, 2016]&#x5728;postag&#x4E0A;&#x7684;&#x8868;&#x73B0;&#xFF1A;<br><img src="/2016/12/10/SyntaxNet Neural-Models-of-Syntax/./1480589639091.png" alt="postag&#x5B9E;&#x9A8C;&#x6548;&#x679C;"></p>
<h4 id="Dependency-Parsing-Transition-Based-Parsing"><a href="#Dependency-Parsing-Transition-Based-Parsing" class="headerlink" title="Dependency Parsing: Transition-Based Parsing"></a>Dependency Parsing: Transition-Based Parsing</h4><p>&#x7B80;&#x5355;&#x4ECB;&#x7ECD;&#x4F9D;&#x5B58;&#x5206;&#x6790;&#x4EFB;&#x52A1;&#xFF0C;&#x8BCD;&#x4E4B;&#x95F4;&#x7684;&#x4F9D;&#x5B58;&#x5173;&#x7CFB;&#x5982;&#x4E0B;&#x56FE;&#xFF1A;<br><img src="/2016/12/10/SyntaxNet Neural-Models-of-Syntax/./1480577956630.png" alt="&#x4F9D;&#x5B58;&#x793A;&#x610F;&#x56FE;"><br>&#x77E5;&#x9053;&#x8BCD;&#x4E4B;&#x95F4;&#x7684;&#x4F9D;&#x5B58;&#x5173;&#x7CFB;&#x6709;&#x52A9;&#x4E8E;&#x6211;&#x4EEC;&#x56DE;&#x7B54;&#x95EE;&#x9898;&#xFF0C;&#x4F8B;&#x5982;&#xFF1A;<br>&#x201C;I saw the man with glasses&#x201D;&#xFF0C;&#x5F97;&#x5230;&#x5982;&#x4E0B;&#x4F9D;&#x5B58;&#x7ED3;&#x6784;&#x540E;&#xFF0C;&#x53EF;&#x4EE5;&#x6BD4;&#x8F83;&#x5BB9;&#x6613;&#x56DE;&#x7B54;&#x201D;whom did I see?, who saw the man with glasses?&#x201D;&#x8FD9;&#x7C7B;&#x95EE;&#x9898;&#x3002;<br>&#x6A21;&#x578B;&#x91C7;&#x7528;arc-standard transition system&#x65B9;&#x5F0F;&#xFF0C;&#x901A;&#x8FC7;&#x5B66;&#x4E60;&#x4E00;&#x7CFB;&#x5217;&#x64CD;&#x4F5C;&#x5F97;&#x5230;&#x53E5;&#x5B50;&#x7684;&#x8BED;&#x6CD5;&#x6811;&#x3002;&#x5B9A;&#x4E49;&#x4E24;&#x4E2A;&#x7ED3;&#x6784;stack&#x548C;buffer&#xFF0C;&#x6709;&#x5982;&#x4E0B;&#x4E09;&#x4E2A;&#x64CD;&#x4F5C;&#x3002;</p>
<ul>
<li><em>SHIFT</em>: &#x5C06;&#x5355;&#x8BCD;&#x653E;&#x5165;stack&#x4E2D;&#x3002;&#x6BD4;&#x4ECE;buffer&#x4E2D;&#x53D6;&#x51FA;&#x4E00;&#x4E2A;&#x8BCD;&#xFF0C;&#x653E;&#x5165;stack</li>
<li><em>LEFT_ARC</em>: &#x4ECE;stack&#x4E2D;&#x53D6;&#x51FA;&#x5934;&#x4E24;&#x4E2A;&#x8BCD;.&#x5C06;&#x7B2C;&#x4E8C;&#x4E2A;&#x8BCD;&#x7684;&#x4F9D;&#x5B58;&#x5173;&#x7CFB;&#x6307;&#x5411;&#x524D;&#x4E00;&#x4E2A;&#xFF0C;&#x7BAD;&#x5934;&#x5411;&#x5DE6;</li>
<li><em>RIGHT_ARC</em>: &#x4ECE;stack&#x4E2D;&#x53D6;&#x51FA;&#x5934;&#x4E24;&#x4E2A;&#x8BCD;&#xFF0C;&#x4E5F;&#x662F;&#x5C06;&#x7B2C;&#x4E8C;&#x4E2A;&#x8BCD;&#x6307;&#x5411;&#x540E;&#x4E00;&#x4E2A;&#x8BCD;&#xFF0C;&#x4F46;&#x7BAD;&#x5934;&#x5411;&#x53F3;</li>
</ul>
<p>&#x6B64;&#x4E3A;&#x4E0A;&#x8FF0;&#x4E09;&#x4E2A;&#x64CD;&#x4F5C;&#x7684;&#x52A8;&#x56FE;&#xFF0C;&#x60F3;&#x4E86;&#x89E3;&#x4F9D;&#x5B58;&#x5206;&#x6790;&#x66F4;&#x591A;&#x77E5;&#x8BC6;&#xFF0C;&#x53EF;&#x4EE5;&#x53C2;&#x770B;&#x8BBA;&#x6587;[<a href="http://www.mitpressjournals.org/doi/pdfplus/10.1162/coli.07-056-R1-07-027" target="_blank" rel="external">2, Nivre  2007</a>] &#xFF1A;<br><img src="/2016/12/10/SyntaxNet Neural-Models-of-Syntax/./1480578966814.gif" alt="(SHIFT) (LEFT_ARC) (RIGHT_ARC) &#x64CD;&#x4F5C;&#x793A;&#x610F;&#x56FE;"><br>&#x5B9E;&#x9A8C;&#x4E2D;&#x4F7F;&#x7528;&#x7684;&#x8BED;&#x6599;&#x4E0E;POS&#x4EFB;&#x52A1;&#x4E00;&#x6837;&#xFF0C;&#x7279;&#x5F81;&#x4E3A;&#x7A97;&#x53E3;&#x5185;&#x7684;&#x8BCD;&#xFF0C;POS&#xFF0C;&#x9644;&#x8FD1;&#x8BCD;&#x7684;&#x4F9D;&#x5B58;&#x5173;&#x7CFB;(&#x9884;&#x6D4B;&#x5F97;&#x5230;&#x7684;k-best&#x7ED3;&#x679C;)</p>
<p>&#x8BAD;&#x597D;&#x7684;&#x6A21;&#x578B;Parsey McParseface&#xFF0C;&#x62A5;&#x544A;&#x6027;&#x80FD;&#x5982;&#x4E0B;&#xFF1A;<br><img src="/2016/12/10/SyntaxNet Neural-Models-of-Syntax/./1480563001353.png" alt="McParseface &#x8BED;&#x6CD5;&#x4F9D;&#x5B58;&#x5206;&#x6790;&#x5B9E;&#x9A8C;&#x6548;&#x679C;"><br>&#x7F51;&#x7EDC;&#x7ED3;&#x6784;&#x548C;&#x524D;&#x8FF0;POS&#x7565;&#x6709;&#x533A;&#x522B;&#xFF0C;&#x5728;softmax&#x5C42;&#x4E0A;&#x589E;&#x52A0;&#x4E86;CRF&#x5C42;&#xFF0C;&#x8BAD;&#x7EC3;&#x6A21;&#x578B;&#x5206;&#x4E24;&#x6B65;&#xFF1A; </p>
<ol>
<li>local: &#x4F7F;&#x7528;&#x5C40;&#x90E8;&#x7684;&#x6570;&#x636E;&#x7A97;&#x53E3;&#x5BF9;&#x6A21;&#x578B;&#x8FDB;&#x884C;pre-train&#xFF0C;&#x8BAD;&#x7EC3;&#x96C6;&#x8BAD;&#x9876;&#x5C42;&#x4E3A;softmax&#x7684;nn&#x7F51;&#x7EDC;&#xFF0C;&#x76EE;&#x6807;&#x51FD;&#x6570;&#x4E3A;&#x5C40;&#x90E8;&#x5F52;&#x4E00;&#x5316;&#x635F;&#x5931;&#x51FD;&#x6570;&#xFF0C;&#x6B64;&#x5904;&#x5F97;&#x5230;&#x5C40;&#x90E8;&#x6A21;&#x578B;&#x3002;&#x8FD9;&#x91CC;&#x548C;&#x524D;&#x9762;&#x8BAD;&#x7EC3;POStag&#x6A21;&#x578B;&#x5F88;&#x50CF;&#xFF0C;&#x4E5F;&#x6709;&#x7528;&#x5230;POStag&#x6A21;&#x578B;&#x7684;&#x8F93;&#x51FA;&#x7ED3;&#x679C;&#x3002;</li>
<li>global: &#x4FDD;&#x7559;&#x9664;&#x4E86;&#x9876;&#x5C42;softmax&#x5C42;&#x5916;&#x5176;&#x4ED6;&#x5C42;&#x7684;&#x53C2;&#x6570;&#xFF0C;&#x7528;&#x5168;&#x5C40;&#x76EE;&#x6807;&#x51FD;&#x6570;&#x8FDB;&#x884C;&#x4E8C;&#x6B21;&#x8BAD;&#x7EC3;&#xFF0C;&#x5F97;&#x5230;&#x5168;&#x5C40;&#x6A21;&#x578B;&#x3002;&#x5728;&#x8BAD;&#x7EC3;&#x8FC7;&#x7A0B;&#x4E2D;&#x6709;&#x4E2A;&#x7EC6;&#x8282;&#xFF0C;&#x5982;&#x679C;&#x5728;&#x67D0;&#x4E2A;&#x4F4D;&#x7F6E;&#x7684;&#x4EBA;&#x5DE5;&#x6807;&#x6CE8;tag&#x843D;&#x5728;beam(beam search&#x7684;&#x7EA6;&#x675F;[3, Bottou, 1997])&#x5916;&#xFF0C;&#x5219;&#x6362;&#x7528;&#x53E6;&#x4E00;&#x4E2A;&#x5305;&#x542B;&#x76EE;&#x6807;&#x6807;&#x7B7E;&#x7684;&#x76EE;&#x6807;&#x51FD;&#x6570;&#x8FDB;&#x884C;&#x68AF;&#x5EA6;&#x8BA1;&#x7B97;&#x3002;</li>
</ol>
<p>&#x5177;&#x4F53;&#x5168;&#x5C40;&#x6A21;&#x578B;&#x548C;&#x5C40;&#x90E8;&#x6A21;&#x578B;&#x7684;&#x7EC6;&#x8282;&#xFF0C;&#x53C2;&#x89C1;[1, Daniel Andor, 2016]&#xFF0C;&#x8FD9;&#x79CD;&#x8BAD;&#x7EC3;&#x65B9;&#x5F0F;&#x548C;&#x7F51;&#x7EDC;&#x7ED3;&#x6784;&#x66F4;&#x65E9;&#x5728;[8, Weiss, 2015]&#x4E2D;&#x53EF;&#x4EE5;&#x770B;&#x5230;&#x3002;&#x6587;&#x4E2D;&#x5BF9;&#x4E8E;&#x4E8C;&#x8005;&#x6027;&#x80FD;&#x5DEE;&#x5F02;&#x8FDB;&#x884C;&#x4E86;&#x7406;&#x8BBA;&#x8BBA;&#x8BC1;&#x3002;&#x8BAD;&#x7EC3;&#x4E2D;&#x91C7;&#x7528;&#x4E0A;&#x8FF0;&#x7ED3;&#x5408;&#x7684;&#x65B9;&#x5F0F;&#xFF0C;&#x80FD;&#x52A0;&#x5FEB;&#x6A21;&#x578B;&#x7684;&#x6536;&#x655B;&#x3002;<br>&#x6CE8;&#xFF1A;&#x7B2C;&#x4E00;&#x5C0F;&#x8282;&#x4ECB;&#x7ECD;POS&#x65F6;&#xFF0C;&#x8BBA;&#x6587;POS&#x5B9E;&#x9A8C;&#x7ED3;&#x679C;&#x6700;&#x597D;&#x7ED3;&#x679C;&#x4E3A;global Normalization&#xFF0C;&#x5F00;&#x6E90;&#x7684;McParseface&#x6587;&#x6863;&#x91CC;&#x5BF9;POS&#x4EFB;&#x52A1;&#x91C7;&#x7528;&#x7684;&#x662F;local Normalization&#xFF0C;&#x8FD9;&#x91CC;&#x9700;&#x8981;&#x505A;&#x533A;&#x5206;&#xFF0C;&#x4E4B;&#x524D;&#x548C;&#x6CE2;&#x5927;&#x795E;&#x804A;&#x7684;&#x65F6;&#x5019;&#x81EA;&#x5DF1;&#x6CA1;&#x770B;&#x6E05;&#x3002;<br><img src="/2016/12/10/SyntaxNet Neural-Models-of-Syntax/./1480592941779.png" alt="&#x56FE;&#x793A;&#xFF1A;&#x5168;&#x5C40;&#x5F52;&#x4E00;&#x5316;SytaxNet&#x7684;&#x793A;&#x610F;&#xFF0C;Beam Search&#x53EF;&#x4EE5;&#x5BF9;&#x5168;&#x5C40;&#x6700;&#x4F18;&#x8FDB;&#x884C;&#x8FD1;&#x4F3C;"></p>
<h4 id="Sentence-Compression"><a href="#Sentence-Compression" class="headerlink" title="Sentence Compression"></a>Sentence Compression</h4><p>&#x53E5;&#x5B50;&#x538B;&#x7F29;&#x5E0C;&#x671B;&#x5728;&#x4E0D;&#x53D1;&#x751F;&#x8F6C;&#x4E49;&#x524D;&#x63D0;&#x4E0B;&#xFF0C;&#x5BF9;&#x53E5;&#x5B50;&#x7684;&#x975E;&#x4E3B;&#x5E72;&#x90E8;&#x5206;&#x8FDB;&#x884C;&#x5220;&#x51CF;&#x3002;<br>&#x57FA;&#x7EBF;&#x4E3A;&#x4E09;&#x5C42;LSTM&#x53E0;&#x52A0;&#x6A21;&#x578B;[4, Filippova, 2015]&#xFF0C;&#x7F51;&#x7EDC;&#x7ED3;&#x6784;&#x5982;&#x4E0B;&#x56FE;&#x3002;decode&#x9636;&#x6BB5;&#x6709;&#x90E8;&#x5206;&#x7EC6;&#x8282;&#x4E0D;&#x540C;&#xFF1A;&#x5148;&#x9006;&#x5E8F;&#x8F93;&#x5165;&#x53E5;&#x5B50;&#x4E2D;&#x6BCF;&#x4E00;&#x4E2A;&#x8BCD;&#xFF0C;&#x518D;&#x6B63;&#x5E8F;&#x8F93;&#x5165;&#x53E5;&#x5B50;&#x4E2D;&#x6BCF;&#x4E00;&#x4E2A;&#x8BCD;&#x5F00;&#x59CB;&#x6253;&#x5206;&#x3002;&#x7528;&#x5230;&#x7684;&#x7279;&#x5F81;&#x4E3A;&#xFF1A;&#x5F53;&#x524D;&#x8BCD;&#x7684;&#x8BCD;&#x5411;&#x91CF;(256&#x7EF4;)[5, Mikolov, 2013]&#xFF0C;&#x524D;&#x8BCD;&#x7684;label(3&#x7EF4;: 1/0/EOF)&#x3002;<br><img src="/2016/12/10/SyntaxNet Neural-Models-of-Syntax/./1480750909667.png" alt="&#x57FA;&#x7EBF;&#x6A21;&#x578B;&#x7ED3;&#x6784;&#x56FE;"><br>&#x57FA;&#x7EBF;&#x5355;&#x5C42;LSTM&#x7ED3;&#x6784;&#xFF0C;&#x8F93;&#x5165;&#x6570;&#x636E;&#x4EE5;&#x56DE;&#x6587;&#x65B9;&#x5F0F;&#x8FDB;&#x884C;&#xFF0C;&#x5E94;&#x8BE5;&#x6709;Bi-directional LSTM&#x7ED3;&#x6784;&#x4E0A;&#x7C7B;&#x4F3C;&#x7684;&#x6548;&#x679C;&#x3002;<br><img src="/2016/12/10/SyntaxNet Neural-Models-of-Syntax/./1481072439671.png" alt="&#x5355;&#x5C42;LSTM&#x7ED3;&#x6784;"></p>
<p>NN&#x7684;&#x8BAD;&#x7EC3;&#x5F80;&#x5F80;&#x9700;&#x8981;&#x5927;&#x91CF;&#x7684;&#x8BED;&#x6599;&#x624D;&#x80FD;&#x4FDD;&#x8BC1;&#x6536;&#x655B;&#xFF0C;&#x57FA;&#x7EBF;&#x7684;&#x4F5C;&#x8005;[6, Filippova, 2013]&#x63D0;&#x51FA;&#x4E86;&#x4E00;&#x79CD;&#x542F;&#x53D1;&#x5F0F;&#x6784;&#x9020;&#x8BED;&#x6599;&#x7684;&#x65B9;&#x6CD5;&#x3002;&#x65B0;&#x95FB;&#x7684;&#x6807;&#x9898;&#x662F;&#x9AD8;&#x6D53;&#x7F29;&#x7684;&#x53E5;&#x5B50;&#xFF0C;&#x4ECE;&#x65B0;&#x95FB;&#x7684;&#x6807;&#x9898;&#x548C;&#x6B63;&#x6587;&#x4E2D;&#x7684;&#x53E5;&#x5B50;&#x91CC;&#xFF0C;&#x62BD;&#x53D6;&#x51FA;&#x6807;&#x9898;&#x5BF9;&#x5E94;&#x7684;&#x539F;&#x53E5;&#xFF0C;&#x7EC4;&#x6210;&#x538B;&#x7F29;&#x53E5;&#x5BF9;(&#x539F;&#x53E5;=&gt;&#x6807;&#x9898;)&#x3002;&#x672C;&#x6587;&#x5B9E;&#x9A8C;&#x4E2D;&#x4F5C;&#x8005;&#x62BD;&#x53D6;&#x4E86;2.3M&#x538B;&#x7F29;&#x53E5;&#x5BF9;&#xFF0C;2M&#x4F5C;&#x4E3A;&#x8BAD;&#x7EC3;&#x96C6;&#xFF0C;130K&#x4F5C;&#x4E3A;&#x5F00;&#x53D1;&#x96C6;&#xFF0C;160K&#x4F5C;&#x4E3A;&#x6D4B;&#x8BD5;&#x96C6;&#x3002;<br>&#x5B9E;&#x9A8C;&#x4E2D;&#x53E5;&#x5B50;&#x538B;&#x7F29;&#x4EFB;&#x52A1;&#x7684;&#x6A21;&#x578B;&#x7ED3;&#x6784;&#x548C;&#x524D;&#x8FF0;&#x4EFB;&#x52A1;&#x4E00;&#x81F4;&#xFF0C;&#x9690;&#x5C42;&#x4E3A;400&#x4E2A;&#x8282;&#x70B9;(&#x4EE3;&#x7801;&#x4E2D;&#x8BBE;&#x5B9A;&#x4E3A;200*200)&#x3002;<br>&#x7279;&#x5F81;&#x8BBE;&#x7F6E;&#xFF1A;&#x7A97;&#x53E3;&#x5185;&#x8BCD;&#x7684;&#x7279;&#x5F81;&#xFF0C;POS&#xFF0C;&#x4F9D;&#x5B58;&#x5173;&#x7CFB;&#xFF0C;&#x524D;&#x8BCD;&#x7684;&#x9884;&#x6D4B;&#x7ED3;&#x679C;&#x3002;&#x5B9E;&#x9A8C;&#x7ED3;&#x679C;&#x5982;&#x4E0B;&#x56FE;&#xFF1A;<br><img src="/2016/12/10/SyntaxNet Neural-Models-of-Syntax/./1480756346351.png" alt="&#x53E5;&#x5B50;&#x538B;&#x7F29;&#x5B9E;&#x9A8C;&#x6548;&#x679C;"></p>
<p>&#x6CE8;&#xFF1A;andor&#x7684;&#x8BBA;&#x6587;pos&#x548C;&#x8BED;&#x6CD5;&#x4F9D;&#x5B58;&#x6548;&#x679C;&#x4E0D;&#x9519;&#xFF0C;&#x53E5;&#x5B50;&#x538B;&#x7F29;&#x8FD9;&#x90E8;&#x5206;&#x5DE5;&#x4F5C;&#x5219;&#x672A;&#x80FD;&#x80DC;&#x8FC7;Filippova&#xFF0C;&#x5982;&#x679C;&#x9700;&#x8981;&#x8C03;&#x7814;&#x5EFA;&#x8BAE;&#x91C7;&#x7528;Filippova&#x8BBA;&#x6587;&#x91CC;&#x7684;&#x65B9;&#x6CD5;&#xFF0C;andor&#x62A5;&#x544A;&#x91CC;&#x901F;&#x5EA6;100&#x500D;&#x4E8E;Filippova&#xFF0C;&#x5E94;&#x8BE5;&#x662F;&#x6CA1;&#x8003;&#x8651;&#x4E86;POS&#x548C;&#x4F9D;&#x5B58;&#x5206;&#x6790;&#x4E24;&#x4E2A;&#x524D;&#x7F6E;&#x4EFB;&#x52A1;&#x7684;&#x8017;&#x65F6;&#xFF0C;&#x5DE5;&#x7A0B;&#x5B9E;&#x73B0;&#x4E0A;&#x901F;&#x5EA6;&#x53EF;&#x80FD;&#x672A;&#x5FC5;&#x6709;&#x4F18;&#x52BF;&#x3002;</p>
<p>[1] Andor D, Alberti C, Weiss D, et al. Globally Normalized Transition-Based Neural Networks[J]. 2016.<br>[2] Nivre2006] Joakim Nivre. 2006. Inductive Dependency Parsing. Springer-Verlag New York, Inc.<br>[3] L&#xB4;eon Bottou, Yann Le Cun, and Yoshua Bengio. 1997. Global training of document processing systems using graph transformer networks. In Proceedings of Computer Vision and Pattern Recognition (CVPR), pages 489&#x2013;493.<br>[4]Filippova K, Alfonseca E, Colmenares C A, et al. Sentence Compression by Deletion with LSTMs[C] Conference on Empirical Methods in Natural Language Processing. 2015.<br>[5] Mikolov, T., I. Sutskever, K. Chen, G. S. Corrado &amp; J. Dean (2013). Distributed representations of words and phrases and their compositionality. In Advances in Neural Information Processing Systems, pp. 3111&#x2013;3119.<br>[6] Filippova K, Altun Y. Overcoming the lack of parallel data in sentence compression[C] 2013.<br>[7] Chen D, Manning C. A Fast and Accurate Dependency Parser using Neural Networks[C]// Conference on Empirical Methods in Natural Language Processing. 2014.<br>[8] Weiss D, Alberti C, Collins M, et al. Structured Training for Neural Network Transition-Based Parsing[J]. Computer Science, 2015.<br>Author&#xFF1A; shawnxiao@baidu</p>
</div><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a data-url="https://mlnote.com/2016/12/10/SyntaxNet Neural-Models-of-Syntax/" data-id="cj1auuqrm000a1slp2g4p09ya" class="article-share-link">分享到</a><div class="tags"><a href="/tags/neural-networks/">neural networks</a><a href="/tags/SyntaxNet/">SyntaxNet</a><a href="/tags/CRF/">CRF</a></div><div class="post-nav"><a href="/2016/12/18/Reading-Notes-of-Word-Embedding/" class="pre">Word Embedding札记</a><a href="/2016/11/18/The-realization-of-GBDT-in-LightGBM-and-FastDBT/" class="next">简述FastDBT和LightGBM中GBDT的实现</a></div><div data-thread-key="2016/12/10/SyntaxNet Neural-Models-of-Syntax/" data-title="简介语法分析开源神经网络SyntaxNet" data-url="https://mlnote.com/2016/12/10/SyntaxNet Neural-Models-of-Syntax/" class="ds-share flat"><div class="ds-share-inline"><ul class="ds-share-icons-16"><li data-toggle="ds-share-icons-more"><a href="javascript:void(0);" class="ds-more">分享到：</a></li><li><a href="javascript:void(0);" data-service="weibo" class="ds-weibo">微博</a></li><li><a href="javascript:void(0);" data-service="qzone" class="ds-qzone">QQ空间</a></li><li><a href="javascript:void(0);" data-service="qqt" class="ds-qqt">腾讯微博</a></li><li><a href="javascript:void(0);" data-service="wechat" class="ds-wechat">微信</a></li></ul><div class="ds-share-icons-more"></div></div></div><div data-thread-key="2016/12/10/SyntaxNet Neural-Models-of-Syntax/" data-title="简介语法分析开源神经网络SyntaxNet" data-url="https://mlnote.com/2016/12/10/SyntaxNet Neural-Models-of-Syntax/" data-author-key="1" class="ds-thread"></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form action="//www.baidu.com/baidu" method="get" accept-charset="utf-8" target="_blank" class="search-form"><input type="search" name="word" maxlength="20" placeholder="Search"/><input type="hidden" name="si" value="https://mlnote.com"/><input name="tn" type="hidden" value="bds"/><input name="cl" type="hidden" value="3"/><input name="ct" type="hidden" value="2097152"/><input name="s" type="hidden" value="on"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/其他/">其他</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/">机器学习</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/gbdt/" style="font-size: 15px;">gbdt</a> <a href="/tags/user-targeting/" style="font-size: 15px;">user targeting</a> <a href="/tags/Batch-Normalization/" style="font-size: 15px;">Batch Normalization</a> <a href="/tags/Caffe/" style="font-size: 15px;">Caffe</a> <a href="/tags/neural-networks/" style="font-size: 15px;">neural-networks</a> <a href="/tags/learning-to-rank/" style="font-size: 15px;">learning to rank</a> <a href="/tags/query-rewriting/" style="font-size: 15px;">query rewriting</a> <a href="/tags/semantic-matching/" style="font-size: 15px;">semantic matching</a> <a href="/tags/deep-learning/" style="font-size: 15px;">deep learning</a> <a href="/tags/error-correction/" style="font-size: 15px;">error correction</a> <a href="/tags/spelling-correction/" style="font-size: 15px;">spelling correction</a> <a href="/tags/neural-networks/" style="font-size: 15px;">neural networks</a> <a href="/tags/word-embedding/" style="font-size: 15px;">word embedding</a> <a href="/tags/SyntaxNet/" style="font-size: 15px;">SyntaxNet</a> <a href="/tags/CRF/" style="font-size: 15px;">CRF</a> <a href="/tags/fastBDT/" style="font-size: 15px;">fastBDT</a> <a href="/tags/advertisement/" style="font-size: 15px;">advertisement</a> <a href="/tags/lightGBM/" style="font-size: 15px;">lightGBM</a> <a href="/tags/RBMs/" style="font-size: 15px;">RBMs</a> <a href="/tags/gbRank/" style="font-size: 15px;">gbRank</a> <a href="/tags/logisticRank/" style="font-size: 15px;">logisticRank</a> <a href="/tags/xgboost/" style="font-size: 15px;">xgboost</a> <a href="/tags/gradient-boosting-framework/" style="font-size: 15px;">gradient boosting framework</a> <a href="/tags/huber/" style="font-size: 15px;">huber</a> <a href="/tags/LST/" style="font-size: 15px;">LST</a> <a href="/tags/LAD/" style="font-size: 15px;">LAD</a> <a href="/tags/classify/" style="font-size: 15px;">classify</a> <a href="/tags/model/" style="font-size: 15px;">model</a> <a href="/tags/bayes/" style="font-size: 15px;">bayes</a> <a href="/tags/code-mannar/" style="font-size: 15px;">code mannar</a> <a href="/tags/hexo/" style="font-size: 15px;">hexo</a> <a href="/tags/mathjex-公式/" style="font-size: 15px;">mathjex 公式</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2017/04/09/Reading-Notes-of-Error-Correction/">一些纠错相关的论文笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/12/20/Neural-Network-Batch-Normalization-and-Caffe-Code/">浅谈Batch Normalization及其Caffe实现</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/12/18/Reading-Notes-of-Word-Embedding/">Word Embedding札记</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/12/10/SyntaxNet Neural-Models-of-Syntax/">简介语法分析开源神经网络SyntaxNet</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/11/18/The-realization-of-GBDT-in-LightGBM-and-FastDBT/">简述FastDBT和LightGBM中GBDT的实现</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/10/29/xgboost-code-review-with-paper/">XGboost核心源码阅读</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/10/05/a-guide-to-xgboost-A-Scalable-Tree-Boosting-System/">XGboost: A Scalable Tree Boosting System论文及源码导读</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/10/02/gradient-boosting-decision-tree-2/">Gradient Boosting Decision Tree[下篇]</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/09/24/gradient-boosting-decision-tree-1/">Gradient Boosting Decision Tree[上篇]</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/09/18/gbRank-logsitRank-from-up-to-bottom/">gbRank & logsitcRank自顶向下</a></li></ul></div><div class="widget"><div class="comments-title"><i class="fa fa-comment-o"> 最近评论</i></div><div data-num-items="5" data-show-avatars="0" data-show-time="1" data-show-admin="0" data-excerpt-length="32" data-show-title="1" class="ds-recent-comments"></div></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://www.example1.com/" title="site-name1" target="_blank">site-name1</a><ul></ul><a href="http://www.example2.com/" title="site-name2" target="_blank">site-name2</a><ul></ul><a href="http://www.example3.com/" title="site-name3" target="_blank">site-name3</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">© <a href="/." rel="nofollow">水滴石穿.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.pack.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="/css/jquery.fancybox.css?v=0.0.0"><script>var duoshuoQuery = {short_name:'qiugen'};
(function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0]
        || document.getElementsByTagName('body')[0]).appendChild(ds);
})();
</script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?ceebf89bb3d2a3b32aff294e42be4ed7";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
  })();
</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>