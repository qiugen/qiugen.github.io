<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="enjoy"><title>水滴石穿 | 无止境探索，保持渴望，无所畏惧</title><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/4.2.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/grids-responsive-min.css"><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.0.0/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">水滴石穿</h1><a id="logo" href="/.">水滴石穿</a><p class="description">无止境探索，保持渴望，无所畏惧</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h2 class="post-title"><a href="/2016/10/05/a-guide-to-xgboost-A-Scalable-Tree-Boosting-System/">xgboost: A Scalable Tree Boosting System论文及源码导读</a></h2><div class="post-meta">2016-10-05</div><a data-thread-key="2016/10/05/a-guide-to-xgboost-A-Scalable-Tree-Boosting-System/" href="/2016/10/05/a-guide-to-xgboost-A-Scalable-Tree-Boosting-System/#comments" class="ds-thread-count"></a><div class="post-content"><p>&#x8FD9;&#x7BC7;&#x8BBA;&#x6587;&#x4E00;&#x4F5C;&#x4E3A;&#x9648;&#x5929;&#x9F50;&#xFF0C;XGBoost&#x662F;&#x4ECE;&#x7ADE;&#x8D5B;pk&#x4E2D;&#x8131;&#x9896;&#x800C;&#x51FA;&#x7684;&#x7B97;&#x6CD5;&#xFF0C;&#x76EE;&#x524D;&#x5F00;&#x6E90;&#x5728;<a href="https://github.com/dmlc/xgboost" target="_blank" rel="external">github</a>&#xFF0C;&#x548C;&#x4F20;&#x7EDF;gbdt&#x65B9;&#x5F0F;&#x4E0D;&#x540C;&#xFF0C;XGBoost&#x5BF9;<em>loss function</em>&#x8FDB;&#x884C;&#x4E86;&#x4E8C;&#x9636;&#x7684;&#x6CF0;&#x52D2;&#x5C55;&#x5F00;&#xFF0C;&#x5E76;&#x589E;&#x52A0;&#x4E86;&#x6B63;&#x5219;&#x9879;&#xFF0C;&#x7528;&#x4E8E;&#x6743;&#x8861;&#x76EE;&#x6807;&#x51FD;&#x6570;&#x7684;&#x4E0B;&#x964D;&#x548C;&#x6A21;&#x578B;&#x7684;&#x590D;&#x6742;&#x5EA6;[12]&#x3002;&#x7F57;&#x5217;&#x4E0B;&#x4F18;&#x52BF;&#xFF1A;</p></div><p class="readmore"><a href="/2016/10/05/a-guide-to-xgboost-A-Scalable-Tree-Boosting-System/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2016/10/02/gradient-boosting-decision-tree-2/">gradient boosting decision tree[下篇]</a></h2><div class="post-meta">2016-10-02</div><a data-thread-key="2016/10/02/gradient-boosting-decision-tree-2/" href="/2016/10/02/gradient-boosting-decision-tree-2/#comments" class="ds-thread-count"></a><div class="post-content"><p>&#x8FD9;&#x7BC7;&#x7B14;&#x8BB0;&#x91CC;&#x9762;&#x4F1A;&#x7EE7;&#x7EED;&#x4ECB;&#x7ECD;<a href="https://qiugen.github.io/2016/09/24/gradient-boosting-decision-tree-1/">&#x4E0A;&#x7BC7;</a>GB&#x7406;&#x8BBA;&#x7684;&#x5177;&#x4F53;&#x7528;&#x6CD5;&#xFF0C;&#x5BF9;&#x4E0D;&#x540C;&#x7684;<code>loss function</code>&#x5C55;&#x5F00;&#x8BA8;&#x8BBA;&#xFF1A;&#x6700;&#x5C0F;&#x5747;&#x65B9;&#x8BEF;&#x5DEE;(LS)&#x548C;&#x6700;&#x5C0F;&#x7EDD;&#x5BF9;&#x503C;&#x8BEF;&#x5DEE;(LAD)&#xFF0C;Huber(M)&#x51FD;&#x6570;&#xFF0C;&#x4E09;&#x8005;&#x4E3B;&#x8981;&#x662F;&#x7528;&#x5728;&#x56DE;&#x5F52;&#x95EE;&#x9898;&#x3002;&#x63A5;&#x7740;&#x518D;&#x770B;GB&#x7406;&#x8BBA;&#x600E;&#x4E48;&#x7528;&#x5728;&#x4E8C;&#x5206;&#x7C7B;&#x548C;&#x591A;&#x5206;&#x7C7B;&#x4E0A;&#x3002;</p></div><p class="readmore"><a href="/2016/10/02/gradient-boosting-decision-tree-2/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2016/09/24/gradient-boosting-decision-tree-1/">gradient boosting decision tree[上篇]</a></h2><div class="post-meta">2016-09-24</div><a data-thread-key="2016/09/24/gradient-boosting-decision-tree-1/" href="/2016/09/24/gradient-boosting-decision-tree-1/#comments" class="ds-thread-count"></a><div class="post-content"><p><a href="https://qiugen.github.io/2016/09/18/gbRank-logsitRank-from-up-to-bottom/">&#x524D;&#x6587;</a>&#x4ECB;&#x7ECD;&#x4E86;gbrank&#x548C;logisticRank&#xFF0C;&#x987A;&#x7740;logisticRank&#x601D;&#x8DEF;&#xFF0C;&#x6211;&#x4EEC;&#x53EF;&#x4EE5;&#x63A5;&#x89E6;&#x5230;gradient boosting&#x6846;&#x67B6;&#x4EE5;&#x53CA;&#x7ECF;&#x5178;&#x7684;gradient boosting decision tree(GBDT)&#x3002;<br>&#x540E;&#x7EED;&#x7684;&#x4ECB;&#x7ECD;&#x4E3B;&#x8981;&#x56DE;&#x7B54;&#x4E0B;&#x9762;&#x4E09;&#x4E2A;&#x95EE;&#x9898;&#xFF1A;</p></div><p class="readmore"><a href="/2016/09/24/gradient-boosting-decision-tree-1/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2016/09/18/gbRank-logsitRank-from-up-to-bottom/">gbRank &amp; logsitcRank自顶向下</a></h2><div class="post-meta">2016-09-18</div><a data-thread-key="2016/09/18/gbRank-logsitRank-from-up-to-bottom/" href="/2016/09/18/gbRank-logsitRank-from-up-to-bottom/#comments" class="ds-thread-count"></a><div class="post-content"><p>&#x4E0A;&#x4E00;&#x7BC7;<a href="https://qiugen.github.io/2016/09/13/Ranking-Relevance-in-Yahoo-Search/">Ranking Relevance in Yahoo Search</a>&#x4E00;&#x6587;&#x4E2D;&#x63D0;&#x5230;&#x7684;logistRank&#x65B9;&#x6CD5;&#x5403;&#x4E0D;&#x592A;&#x900F;&#xFF0C;&#x6CA1;&#x5C55;&#x5F00;&#x3002;&#x8FD9;&#x4E24;&#x5929;&#x521A;&#x597D;&#x4E2D;&#x79CB;&#xFF0C;&#x6574;&#x7406;&#x51FA;&#x6765;&#x3002;<br>&#x4ECB;&#x7ECD;&#x601D;&#x8DEF;&#x5982;&#x4E0B;&#xFF1A;    </p></div><p class="readmore"><a href="/2016/09/18/gbRank-logsitRank-from-up-to-bottom/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2016/09/13/Ranking-Relevance-in-Yahoo-Search/">[笔记]Ranking Relevance in Yahoo Search</a></h2><div class="post-meta">2016-09-13</div><a data-thread-key="2016/09/13/Ranking-Relevance-in-Yahoo-Search/" href="/2016/09/13/Ranking-Relevance-in-Yahoo-Search/#comments" class="ds-thread-count"></a><div class="post-content"><p>&#x6587;&#x7AE0;&#x4ECB;&#x7ECD;&#x4E86;&#x96C5;&#x864E;&#x5728;&#x4F18;&#x5316;&#x641C;&#x7D22;&#x5F15;&#x64CE;&#x6392;&#x5E8F;&#x7684;&#x90E8;&#x5206;&#x5DE5;&#x4F5C;&#xFF0C;&#x4E3B;&#x8981;&#x4ECB;&#x7ECD;&#x4E86;&#x6392;&#x5E8F;&#x51FD;&#x6570;(ranking function), &#x8BED;&#x4E49;&#x76F8;&#x4F3C;&#x7279;&#x5F81;(semantic matching features), &#x6539;&#x5199;(query rewriting)&#x3002;&#x7ED9;&#x51FA;&#x4E86;&#x68C0;&#x7D22;&#x7ED3;&#x679C;&#x540C;&#x65F6;&#x6EE1;&#x8DB3;&#x65F6;&#x6548;&#x6027;&#x548C;&#x5730;&#x7406;&#x4F4D;&#x7F6E;&#x76F8;&#x5173;&#x5EA6;&#x7684;&#x89E3;&#x51B3;&#x65B9;&#x6848;&#x3002;</p></div><p class="readmore"><a href="/2016/09/13/Ranking-Relevance-in-Yahoo-Search/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2016/09/03/Large-scale-behavioral-user-targeting/">[笔记]Large-scale behavioral user targeting</a></h2><div class="post-meta">2016-09-03</div><a data-thread-key="2016/09/03/Large-scale-behavioral-user-targeting/" href="/2016/09/03/Large-scale-behavioral-user-targeting/#comments" class="ds-thread-count"></a><div class="post-content"><p>&#x7528;&#x6237;&#x884C;&#x4E3A;&#x5B9A;&#x5411;&#x7684;&#x76EE;&#x7684;&#x662F;&#x6839;&#x636E;&#x7528;&#x6237;&#x7684;&#x5386;&#x53F2;&#x884C;&#x4E3A;&#xFF0C;&#x6765;&#x9009;&#x62E9;&#x6700;&#x5408;&#x9002;&#x7684;&#x5E7F;&#x544A;&#x6295;&#x653E;&#xFF0C;&#x6309;&#x5982;&#x4E0B;&#x601D;&#x8DEF;&#x4ECB;&#x7ECD;&#xFF1A;</p></div><p class="readmore"><a href="/2016/09/03/Large-scale-behavioral-user-targeting/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2016/09/03/solved-mathjex-problem/">解决hexo(jekyll) mathjex 插入公式后渲染问题</a></h2><div class="post-meta">2016-09-03</div><a data-thread-key="2016/09/03/solved-mathjex-problem/" href="/2016/09/03/solved-mathjex-problem/#comments" class="ds-thread-count"></a><div class="post-content"><p>&#x7531;&#x4E8E;latex&#x516C;&#x5F0F;&#x4E2D;&#x7ECF;&#x5E38;&#x6709;&#x4E24;&#x4E2A;&#x82B1;&#x62EC;&#x53F7;&#x201C;{{&#x201D;&#x5B58;&#x5728;&#xFF0C;&#x800C;jekyll&#x548C;hexo&#x90FD;&#x4F1A;&#x89E3;&#x6790;&#x8FD9;&#x4E2A;&#x6837;&#x5F0F;<br>&#x5BFC;&#x81F4;&#x5982;&#x4E0B;&#x62A5;&#x9519;&#xFF1A;<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">FATAL (unknown path) [Line 2, Column 166]</div><div class="line">  parseAggregate: expected colon after dict key</div><div class="line">Template render error: (unknown path) [Line 2, Column 166]</div><div class="line">  parseAggregate: expected colon after dict key</div></pre></td></tr></table></figure></p></div><p class="readmore"><a href="/2016/09/03/solved-mathjex-problem/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2014/05/11/Training-Products-of-Experts-by-Minimizing-Contrastive-Divergence/">[笔记]Training Products of Experts by Minimizing Contrastive Divergence</a></h2><div class="post-meta">2014-05-11</div><a data-thread-key="2014/05/11/Training-Products-of-Experts-by-Minimizing-Contrastive-Divergence/" href="/2014/05/11/Training-Products-of-Experts-by-Minimizing-Contrastive-Divergence/#comments" class="ds-thread-count"></a><div class="post-content"><p> &#x8FD9;&#x7BC7;&#x6587;&#x7AE0;&#x521D;&#x89C1;&#x5728;hinton 2006 A Practical Guide to Training Restricted Boltzmann Machines,&#x4E0B;&#x79F0;&#x300A;Guide&#x300B;&#x3002;&#x300A;Guide&#x300B;&#x4E3B;&#x8981;&#x4ECB;&#x7ECD;&#x8BAD;&#x7EC3;DBM&#x7684;&#x7B97;&#x6CD5;&#x6D41;&#x7A0B;&#x548C;&#x53C2;&#x6570;&#x8BBE;&#x7F6E;&#x7EC6;&#x8282;&#x3002;&#x5728;&#x8FD9;&#x4E00;&#x5E74;&#xFF0C;&#x6211;&#x4EEC;&#x53EF;&#x4EE5;&#x770B;&#x5230;&#x5927;&#x725B;hinton&#x7684;&#x65E0;&#x79C1;&#x8D21;&#x732E;&#xFF0C;&#x5355;&#x662F;2006&#x5E74;&#x5C31;&#x6709;&#x4E24;&#x7BC7;&#x6587;&#x7AE0;&#x300A;A fast learning algorithm for deep belief nets&#x300B;&#x53CA;&#x5176;&#x9644;&#x5F55;&#x4E2D;&#x7684;&#x8BBA;&#x8BC1;&#x548C;&#x4F2A;&#x4EE3;&#x7801;&#x548C;SCIENCE&#x4E0A;&#x7684;&#x5927;&#x4F5C;&#x300A;Reducing the Dimensionality of Data with Neural Networks&#x300B;&#x548C;&#x76F8;&#x5E94;&#x7684;<a href="https://www.sciencemag.org/content/313/5786/504/suppl/DC1#below" target="_blank" rel="external">&#x7F51;&#x7AD9;&#x8D44;&#x6599;</a>&#x3002;&#x6750;&#x6599;&#x4E4B;&#x5168;&#x9762;&#xFF0C;&#x656C;&#x4EF0;&#xFF0C;&#x53CD;&#x590D;&#x7814;&#x8BFB;&#xFF0C;&#x5BF9;&#x8BAD;&#x7EC3;RBM&#x8FD9;&#x4E8B;&#x6709;&#x4E86;&#x70B9;&#x7709;&#x76EE;&#xFF0C;&#x6015;&#x81EA;&#x5DF1;&#x8BB0;&#x6027;&#x4E0D;&#x597D;&#x7ED9;&#x5FD8;&#x4E86;&#xFF0C;&#x7D22;&#x6027;&#x4E66;&#x5199;&#x4E0B;&#x6765;&#x3002;</p></div><p class="readmore"><a href="/2014/05/11/Training-Products-of-Experts-by-Minimizing-Contrastive-Divergence/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2014/03/02/naive-bayes-classify/">朴素贝叶斯分类算法简介</a></h2><div class="post-meta">2014-03-02</div><a data-thread-key="2014/03/02/naive-bayes-classify/" href="/2014/03/02/naive-bayes-classify/#comments" class="ds-thread-count"></a><div class="post-content"><p>&#x672C;&#x7BC7;&#x4E3B;&#x8981;&#x4ECB;&#x7ECD;&#x8D1D;&#x53F6;&#x65AF;&#x5206;&#x7C7B;&#x7B97;&#x6CD5;&#x4E2D;&#x7684;&#x6734;&#x7D20;&#x8D1D;&#x53F6;&#x65AF;&#x4EE5;&#x53CA;&#x591A;&#x9879;&#x5F0F;&#x6A21;&#x578B;&#xFF0C;&#x4EE5;&#x53CA;&#x5904;&#x7406;&#x8FDE;&#x7EED;&#x53D8;&#x91CF;&#x7684;&#x9AD8;&#x65AF;&#x6A21;&#x578B;&#x3002;</p></div><p class="readmore"><a href="/2014/03/02/naive-bayes-classify/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2013/05/29/徐志摩诗一首/">再休怪我的脸沉</a></h2><div class="post-meta">2013-05-29</div><a data-thread-key="2013/05/29/徐志摩诗一首/" href="/2013/05/29/徐志摩诗一首/#comments" class="ds-thread-count"></a><div class="post-content"><p>&#x5F90;&#x5FD7;&#x6469;&#x8BD7;&#x96C6;&#x300A;&#x7FE1;&#x51B7;&#x7FE0;&#x7684;&#x591C;&#x300B;&#x4E2D;&#x8BD7;&#x4E00;&#x9996;  </p></div><p class="readmore"><a href="/2013/05/29/徐志摩诗一首/">阅读更多</a></p></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form action="//www.baidu.com/baidu" method="get" accept-charset="utf-8" target="_blank" class="search-form"><input type="search" name="word" maxlength="20" placeholder="Search"/><input type="hidden" name="si" value="https://qiugen.github.io"/><input name="tn" type="hidden" value="bds"/><input name="cl" type="hidden" value="3"/><input name="ct" type="hidden" value="2097152"/><input name="s" type="hidden" value="on"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/其他/">其他</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/">机器学习</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/LST/" style="font-size: 15px;">LST</a> <a href="/tags/learning-to-rank/" style="font-size: 15px;">learning to rank</a> <a href="/tags/semantic-matching/" style="font-size: 15px;">semantic matching</a> <a href="/tags/deep-learning/" style="font-size: 15px;">deep learning</a> <a href="/tags/gbRank/" style="font-size: 15px;">gbRank</a> <a href="/tags/logisticRank/" style="font-size: 15px;">logisticRank</a> <a href="/tags/gbdt/" style="font-size: 15px;">gbdt</a> <a href="/tags/gradient-boosting-framework/" style="font-size: 15px;">gradient boosting framework</a> <a href="/tags/RBMs/" style="font-size: 15px;">RBMs</a> <a href="/tags/huber/" style="font-size: 15px;">huber</a> <a href="/tags/query-rewriting/" style="font-size: 15px;">query rewriting</a> <a href="/tags/LAD/" style="font-size: 15px;">LAD</a> <a href="/tags/classify/" style="font-size: 15px;">classify</a> <a href="/tags/model/" style="font-size: 15px;">model</a> <a href="/tags/bayes/" style="font-size: 15px;">bayes</a> <a href="/tags/xgboost/" style="font-size: 15px;">xgboost</a> <a href="/tags/user-targeting/" style="font-size: 15px;">user targeting</a> <a href="/tags/advertisement/" style="font-size: 15px;">advertisement</a> <a href="/tags/hexo/" style="font-size: 15px;">hexo</a> <a href="/tags/mathjex-公式/" style="font-size: 15px;">mathjex 公式</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2016/10/05/a-guide-to-xgboost-A-Scalable-Tree-Boosting-System/">xgboost: A Scalable Tree Boosting System论文及源码导读</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/10/02/gradient-boosting-decision-tree-2/">gradient boosting decision tree[下篇]</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/09/24/gradient-boosting-decision-tree-1/">gradient boosting decision tree[上篇]</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/09/18/gbRank-logsitRank-from-up-to-bottom/">gbRank & logsitcRank自顶向下</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/09/13/Ranking-Relevance-in-Yahoo-Search/">[笔记]Ranking Relevance in Yahoo Search</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/09/03/Large-scale-behavioral-user-targeting/">[笔记]Large-scale behavioral user targeting</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/09/03/solved-mathjex-problem/">解决hexo(jekyll) mathjex 插入公式后渲染问题</a></li><li class="post-list-item"><a class="post-list-link" href="/2014/05/11/Training-Products-of-Experts-by-Minimizing-Contrastive-Divergence/">[笔记]Training Products of Experts by Minimizing Contrastive Divergence</a></li><li class="post-list-item"><a class="post-list-link" href="/2014/03/02/naive-bayes-classify/">朴素贝叶斯分类算法简介</a></li><li class="post-list-item"><a class="post-list-link" href="/2013/05/29/徐志摩诗一首/">再休怪我的脸沉</a></li></ul></div><div class="widget"><div class="comments-title"><i class="fa fa-comment-o"> 最近评论</i></div><div data-num-items="5" data-show-avatars="0" data-show-time="1" data-show-admin="0" data-excerpt-length="32" data-show-title="1" class="ds-recent-comments"></div></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://www.example1.com/" title="site-name1" target="_blank">site-name1</a><ul></ul><a href="http://www.example2.com/" title="site-name2" target="_blank">site-name2</a><ul></ul><a href="http://www.example3.com/" title="site-name3" target="_blank">site-name3</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">© <a href="/." rel="nofollow">水滴石穿.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.pack.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="/css/jquery.fancybox.css?v=0.0.0"><script>var duoshuoQuery = {short_name:'qiugen'};
(function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0]
        || document.getElementsByTagName('body')[0]).appendChild(ds);
})();
</script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>