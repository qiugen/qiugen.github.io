<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="enjoy"><title>水滴石穿 | 探索，保持渴望，无所畏惧</title><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/4.2.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/grids-responsive-min.css"><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.0.0/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">水滴石穿</h1><a id="logo" href="/.">水滴石穿</a><p class="description">探索，保持渴望，无所畏惧</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h2 class="post-title"><a href="/2016/12/20/Neural-Network-Batch-Normalization-and-Caffe-Code/">浅谈Batch Normalization及其Caffe实现</a></h2><div class="post-meta">2016-12-20</div><a data-thread-key="2016/12/20/Neural-Network-Batch-Normalization-and-Caffe-Code/" href="/2016/12/20/Neural-Network-Batch-Normalization-and-Caffe-Code/#comments" class="ds-thread-count"></a><div class="post-content"><p><strong>&#x6458;&#x8981;:</strong>2015&#x5E74;2&#x6708;&#x4EFD;&#xFF0C;Google&#x548C;MSRA&#x7684;paper&#x76F8;&#x7EE7;&#x5728;<a href="https://arxiv.org/" target="_blank" rel="external">arxiv.org</a>&#x4E0A;&#x6A2A;&#x7A7A;&#x51FA;&#x4E16;&#xFF0C;&#x5BA3;&#x5E03;&#x5728;ImagenNet&#x56FE;&#x50CF;&#x6570;&#x636E;&#x96C6;&#x4E0A;&#x53D6;&#x5F97;&#x4E86;&#x6BD4;&#x4EBA;&#x7C7B;&#x66F4;&#x9AD8;&#x7684;&#x8BC6;&#x522B;&#x80FD;&#x529B;. &#x6B64;&#x7A81;&#x7834;&#x610F;&#x4E49;&#x91CD;&#x5927;&#xFF0C;&#x6587;&#x7AE0;&#x53D1;&#x5E03;&#x540E;&#x5F15;&#x8D77;&#x4E00;&#x7247;&#x70ED;&#x6F6E;&#xFF0C;&#x5728;&#x56FE;&#x50CF;&#x9886;&#x57DF;&#x5177;&#x6709;&#x666E;&#x9002;&#x7684;&#x5E94;&#x7528;.<br>&#x672C;&#x6587;&#x4E2D;&#x7B14;&#x8005;&#x4EC5;&#x5C31;Google&#x7684;Batch Normalization&#x8C08;&#x8C08;&#x7C97;&#x6D45;&#x7684;&#x7406;&#x89E3;.     </p></div><p class="readmore"><a href="/2016/12/20/Neural-Network-Batch-Normalization-and-Caffe-Code/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2016/12/18/Reading-Notes-of-Word-Embedding/">Word Embedding札记</a></h2><div class="post-meta">2016-12-18</div><a data-thread-key="2016/12/18/Reading-Notes-of-Word-Embedding/" href="/2016/12/18/Reading-Notes-of-Word-Embedding/#comments" class="ds-thread-count"></a><div class="post-content"><p>&#x5982;&#x4F55;&#x5229;&#x7528;&#x6587;&#x672C;&#x7684;&#x4E0A;&#x4E0B;&#x6587;&#x4FE1;&#x606F;&#xFF0C;&#x5F97;&#x5230;&#x66F4;&#x6709;&#x610F;&#x4E49;&#x7684;&#x5411;&#x91CF;&#x8868;&#x8FBE;(word embedding)&#xFF0C;&#x662F;NLP&#x9886;&#x57DF;&#x7814;&#x7A76;&#x7684;&#x91CD;&#x70B9;&#x3002;&#x672C;&#x7BC7;&#x7B14;&#x8BB0;&#x76EE;&#x7684;&#x5728;&#x4E8E;&#x6574;&#x7406;&#x8BCD;&#x5411;&#x91CF;&#x7684;&#x53D1;&#x5C55;&#x5386;&#x7A0B;&#xFF0C;&#x65B9;&#x4FBF;&#x7406;&#x89E3;&#x4EC0;&#x4E48;&#x662F;&#x8BCD;&#x5411;&#x91CF;&#xFF0C;&#x600E;&#x4E48;&#x5F97;&#x5230;&#x8BCD;&#x5411;&#x91CF;&#x3002;&#x8BCD;&#x5411;&#x91CF;&#x4E5F;&#x53EB;&#x8BCD;&#x7684;&#x5206;&#x5E03;&#x5F0F;&#x8868;&#x8FBE;&#xFF0C;&#x4E3B;&#x8981;&#x6709;&#x4E09;&#x7C7B;&#x65B9;&#x6CD5;&#xFF1A;&#x805A;&#x7C7B;&#xFF0C;&#x77E9;&#x9635;&#x5206;&#x89E3;&#xFF0C;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x3002;</p></div><p class="readmore"><a href="/2016/12/18/Reading-Notes-of-Word-Embedding/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2016/12/10/SyntaxNet Neural-Models-of-Syntax/">简介语法分析开源神经网络SyntaxNet</a></h2><div class="post-meta">2016-12-10</div><a data-thread-key="2016/12/10/SyntaxNet Neural-Models-of-Syntax/" href="/2016/12/10/SyntaxNet Neural-Models-of-Syntax/#comments" class="ds-thread-count"></a><div class="post-content"><p>SyntaxNet&#x5728;github&#x6587;&#x6863;&#x5F00;&#x6E90;&#x90E8;&#x5206;&#x4ECB;&#x7ECD;&#x4E86;&#x4E24;&#x4E2A;&#x6A21;&#x578B;&#xFF1A;&#x8BCD;&#x6027;&#x6807;&#x6CE8;&#x548C;&#x8BED;&#x6CD5;&#x4F9D;&#x5B58;&#x5206;&#x6790;&#xFF0C;&#x8BBA;&#x6587;&#x4E2D;&#x8FD8;&#x6709;&#x53E5;&#x5B50;&#x538B;&#x7F29;&#x90E8;&#x5206;&#x5185;&#x5BB9;&#x3002;[<a href="https://github.com/tensorflow/models/tree/master/syntaxnet#annotating-a-corpus" target="_blank" rel="external">github&#x5730;&#x5740;</a>]&#xFF0C;[<a href="https://github.com/tensorflow/models/tree/master/syntaxnet#annotating-a-corpus" target="_blank" rel="external">&#x76F8;&#x5173;&#x6587;&#x6863;</a>], [<a href="https://arxiv.org/abs/1603.06042" target="_blank" rel="external">&#x5BF9;&#x5E94;&#x8BBA;&#x6587;</a> ]&#x3002;<br>&#x5BF9;&#x5E94;&#x8BBA;&#x6587;&#x4E00;&#x4F5C;&#x4E3A;andor&#xFF0C;&#x9488;&#x5BF9;&#x4E09;&#x4E2A;&#x4EFB;&#x52A1;&#xFF0C;&#x6E10;&#x8FDB;&#x5F0F;&#x4ECB;&#x7ECD;&#x4E86;&#x8BCD;&#x6027;&#x6807;&#x6CE8;(part-of-speech)&#xFF0C;&#x4F9D;&#x5B58;&#x5206;&#x6790;&#xFF0C;&#x53E5;&#x5B50;&#x538B;&#x7F29;&#x4E09;&#x4E2A;&#x90E8;&#x5206;&#x5DE5;&#x4F5C;&#x3002;&#x4F9D;&#x5B58;&#x5206;&#x6790;&#x4F7F;&#x7528;&#x4E86;&#x8BCD;&#x6027;&#x6807;&#x6CE8;&#x7684;&#x8F93;&#x51FA;&#x4F5C;&#x4E3A;&#x8F93;&#x5165;&#x7279;&#x5F81;&#xFF0C;&#x800C;&#x53E5;&#x5B50;&#x538B;&#x7F29;&#x5219;&#x7528;&#x4E86;&#x524D;&#x4E24;&#x4E2A;&#x4EFB;&#x52A1;&#x7684;&#x7ED3;&#x679C;&#x4F5C;&#x4E3A;&#x8F93;&#x5165;&#x7279;&#x5F81;&#x3002; &#x63A5;&#x4E0B;&#x6765;&#x987A;&#x5E8F;&#x4ECB;&#x7ECD;&#x4E0B;&#x4E09;&#x4E2A;&#x5DE5;&#x4F5C;&#xFF1A;</p></div><p class="readmore"><a href="/2016/12/10/SyntaxNet Neural-Models-of-Syntax/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2016/11/18/The-realization-of-GBDT-in-LightGBM-and-FastDBT/">简述FastDBT和LightGBM中GBDT的实现</a></h2><div class="post-meta">2016-11-18</div><a data-thread-key="2016/11/18/The-realization-of-GBDT-in-LightGBM-and-FastDBT/" href="/2016/11/18/The-realization-of-GBDT-in-LightGBM-and-FastDBT/#comments" class="ds-thread-count"></a><div class="post-content"><p>FastDBT&#x548C;LightGBM&#x5728;XGBoost&#x4E4B;&#x540E;&#x63D0;&#x51FA;&#xFF0C;FastBDT&#x9488;&#x5BF9;&#x591A;&#x7C7B;&#x522B;&#x95EE;&#x9898;&#x8FDB;&#x884C;&#x4E86;&#x4F18;&#x5316;&#xFF0C;&#x4ECE;&#x5B9E;&#x73B0;&#x5C42;&#x9762;&#x83B7;&#x5F97;&#x4E86;&#x66F4;&#x5FEB;&#x7684;&#x8BAD;&#x7EC3;&#x901F;&#x5EA6;&#xFF0C;LightGBM&#x5219;&#x5728;&#x6811;&#x7684;&#x751F;&#x6210;&#x8FDB;&#x884C;&#x4E86;&#x6539;&#x8FDB;&#xFF0C;&#x6587;&#x7AE0;&#x6309;&#x4EE5;&#x4E0B;&#x601D;&#x8DEF;&#x4ECB;&#x7ECD;</p></div><p class="readmore"><a href="/2016/11/18/The-realization-of-GBDT-in-LightGBM-and-FastDBT/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2016/10/29/xgboost-code-review-with-paper/">XGboost核心源码阅读</a></h2><div class="post-meta">2016-10-29</div><a data-thread-key="2016/10/29/xgboost-code-review-with-paper/" href="/2016/10/29/xgboost-code-review-with-paper/#comments" class="ds-thread-count"></a><div class="post-content"><p>&#x4E0A;&#x7BC7;&#x300A;<a href="http://mlnote.com/2016/10/05/a-guide-to-xgboost-A-Scalable-Tree-Boosting-System/">xgboost: A Scalable Tree Boosting System&#x8BBA;&#x6587;&#x53CA;&#x6E90;&#x7801;&#x5BFC;&#x8BFB;</a>&#x300B;&#x4ECB;&#x7ECD;&#x4E86;xgboost&#x7684;&#x6846;&#x67B6;&#x548C;&#x4EE3;&#x7801;&#x7ED3;&#x6784;&#x3002;&#x672C;&#x7BC7;&#x5C06;&#x7EE7;&#x7EED;&#x8BA8;&#x8BBA;&#x4EE3;&#x7801;&#x7EC6;&#x8282;&#xFF0C;&#x53EF;&#x80FD;&#x6BD4;&#x8F83;&#x67AF;&#x71E5;&#xFF0C;&#x575A;&#x6301;&#x4E00;&#x4E0B;&#x54C8;&#x3002;<br>&#x63A5;&#x4E0B;&#x6765;&#x6309;&#x8FD9;&#x4E2A;&#x987A;&#x5E8F;&#x6574;&#x7406;&#x7B14;&#x8BB0;&#xFF0C;&#x4ECB;&#x7ECD;xgboost&#x7684;&#x6838;&#x5FC3;&#x4EE3;&#x7801;&#xFF1A;</p></div><p class="readmore"><a href="/2016/10/29/xgboost-code-review-with-paper/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2016/10/05/a-guide-to-xgboost-A-Scalable-Tree-Boosting-System/">XGboost: A Scalable Tree Boosting System论文及源码导读</a></h2><div class="post-meta">2016-10-05</div><a data-thread-key="2016/10/05/a-guide-to-xgboost-A-Scalable-Tree-Boosting-System/" href="/2016/10/05/a-guide-to-xgboost-A-Scalable-Tree-Boosting-System/#comments" class="ds-thread-count"></a><div class="post-content"><p>&#x8FD9;&#x7BC7;&#x8BBA;&#x6587;&#x4E00;&#x4F5C;&#x4E3A;&#x9648;&#x5929;&#x9F50;&#xFF0C;XGBoost&#x662F;&#x4ECE;&#x7ADE;&#x8D5B;pk&#x4E2D;&#x8131;&#x9896;&#x800C;&#x51FA;&#x7684;&#x7B97;&#x6CD5;&#xFF0C;&#x76EE;&#x524D;&#x5F00;&#x6E90;&#x5728;<a href="https://github.com/dmlc/xgboost" target="_blank" rel="external">github</a>&#xFF0C;&#x548C;&#x4F20;&#x7EDF;gbdt&#x65B9;&#x5F0F;&#x4E0D;&#x540C;&#xFF0C;XGBoost&#x5BF9;<em>loss function</em>&#x8FDB;&#x884C;&#x4E86;&#x4E8C;&#x9636;&#x7684;&#x6CF0;&#x52D2;&#x5C55;&#x5F00;&#xFF0C;&#x5E76;&#x589E;&#x52A0;&#x4E86;&#x6B63;&#x5219;&#x9879;&#xFF0C;&#x7528;&#x4E8E;&#x6743;&#x8861;&#x76EE;&#x6807;&#x51FD;&#x6570;&#x7684;&#x4E0B;&#x964D;&#x548C;&#x6A21;&#x578B;&#x7684;&#x590D;&#x6742;&#x5EA6;[12]&#x3002;&#x7F57;&#x5217;&#x4E0B;&#x4F18;&#x52BF;&#xFF1A;</p></div><p class="readmore"><a href="/2016/10/05/a-guide-to-xgboost-A-Scalable-Tree-Boosting-System/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2016/10/02/gradient-boosting-decision-tree-2/">Gradient Boosting Decision Tree[下篇]</a></h2><div class="post-meta">2016-10-02</div><a data-thread-key="2016/10/02/gradient-boosting-decision-tree-2/" href="/2016/10/02/gradient-boosting-decision-tree-2/#comments" class="ds-thread-count"></a><div class="post-content"><p>&#x8FD9;&#x7BC7;&#x7B14;&#x8BB0;&#x91CC;&#x9762;&#x4F1A;&#x7EE7;&#x7EED;&#x4ECB;&#x7ECD;<a href="https://qiugen.github.io/2016/09/24/gradient-boosting-decision-tree-1/" target="_blank" rel="external">&#x4E0A;&#x7BC7;</a>GB&#x7406;&#x8BBA;&#x7684;&#x5177;&#x4F53;&#x7528;&#x6CD5;&#xFF0C;&#x5BF9;&#x4E0D;&#x540C;&#x7684;<code>loss function</code>&#x5C55;&#x5F00;&#x8BA8;&#x8BBA;&#xFF1A;&#x6700;&#x5C0F;&#x5747;&#x65B9;&#x8BEF;&#x5DEE;(LS)&#x548C;&#x6700;&#x5C0F;&#x7EDD;&#x5BF9;&#x503C;&#x8BEF;&#x5DEE;(LAD)&#xFF0C;Huber(M)&#x51FD;&#x6570;&#xFF0C;&#x4E09;&#x8005;&#x4E3B;&#x8981;&#x662F;&#x7528;&#x5728;&#x56DE;&#x5F52;&#x95EE;&#x9898;&#x3002;&#x63A5;&#x7740;&#x518D;&#x770B;GB&#x7406;&#x8BBA;&#x600E;&#x4E48;&#x7528;&#x5728;&#x4E8C;&#x5206;&#x7C7B;&#x548C;&#x591A;&#x5206;&#x7C7B;&#x4E0A;&#x3002;</p></div><p class="readmore"><a href="/2016/10/02/gradient-boosting-decision-tree-2/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2016/09/24/gradient-boosting-decision-tree-1/">Gradient Boosting Decision Tree[上篇]</a></h2><div class="post-meta">2016-09-24</div><a data-thread-key="2016/09/24/gradient-boosting-decision-tree-1/" href="/2016/09/24/gradient-boosting-decision-tree-1/#comments" class="ds-thread-count"></a><div class="post-content"><p><a href="https://qiugen.github.io/2016/09/18/gbRank-logsitRank-from-up-to-bottom/" target="_blank" rel="external">&#x524D;&#x6587;</a>&#x4ECB;&#x7ECD;&#x4E86;gbrank&#x548C;logisticRank&#xFF0C;&#x987A;&#x7740;logisticRank&#x601D;&#x8DEF;&#xFF0C;&#x6211;&#x4EEC;&#x53EF;&#x4EE5;&#x63A5;&#x89E6;&#x5230;gradient boosting&#x6846;&#x67B6;&#x4EE5;&#x53CA;&#x7ECF;&#x5178;&#x7684;gradient boosting decision tree(GBDT)&#x3002;<br>&#x540E;&#x7EED;&#x7684;&#x4ECB;&#x7ECD;&#x4E3B;&#x8981;&#x56DE;&#x7B54;&#x4E0B;&#x9762;&#x4E09;&#x4E2A;&#x95EE;&#x9898;&#xFF1A;</p></div><p class="readmore"><a href="/2016/09/24/gradient-boosting-decision-tree-1/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2016/09/18/gbRank-logsitRank-from-up-to-bottom/">gbRank &amp; logsitcRank自顶向下</a></h2><div class="post-meta">2016-09-18</div><a data-thread-key="2016/09/18/gbRank-logsitRank-from-up-to-bottom/" href="/2016/09/18/gbRank-logsitRank-from-up-to-bottom/#comments" class="ds-thread-count"></a><div class="post-content"><p>&#x4E0A;&#x4E00;&#x7BC7;<a href="https://qiugen.github.io/2016/09/13/Ranking-Relevance-in-Yahoo-Search/" target="_blank" rel="external">Ranking Relevance in Yahoo Search</a>&#x4E00;&#x6587;&#x4E2D;&#x63D0;&#x5230;&#x7684;logistRank&#x65B9;&#x6CD5;&#x5403;&#x4E0D;&#x592A;&#x900F;&#xFF0C;&#x6CA1;&#x5C55;&#x5F00;&#x3002;&#x8FD9;&#x4E24;&#x5929;&#x521A;&#x597D;&#x4E2D;&#x79CB;&#xFF0C;&#x6574;&#x7406;&#x51FA;&#x6765;&#x3002;<br>&#x4ECB;&#x7ECD;&#x601D;&#x8DEF;&#x5982;&#x4E0B;&#xFF1A;    </p></div><p class="readmore"><a href="/2016/09/18/gbRank-logsitRank-from-up-to-bottom/">阅读更多</a></p></div><div class="post"><h2 class="post-title"><a href="/2016/09/13/Ranking-Relevance-in-Yahoo-Search/">[笔记]Ranking Relevance in Yahoo Search</a></h2><div class="post-meta">2016-09-13</div><a data-thread-key="2016/09/13/Ranking-Relevance-in-Yahoo-Search/" href="/2016/09/13/Ranking-Relevance-in-Yahoo-Search/#comments" class="ds-thread-count"></a><div class="post-content"><p>&#x6587;&#x7AE0;&#x4ECB;&#x7ECD;&#x4E86;&#x96C5;&#x864E;&#x5728;&#x4F18;&#x5316;&#x641C;&#x7D22;&#x5F15;&#x64CE;&#x6392;&#x5E8F;&#x7684;&#x90E8;&#x5206;&#x5DE5;&#x4F5C;&#xFF0C;&#x4E3B;&#x8981;&#x4ECB;&#x7ECD;&#x4E86;&#x6392;&#x5E8F;&#x51FD;&#x6570;(ranking function), &#x8BED;&#x4E49;&#x76F8;&#x4F3C;&#x7279;&#x5F81;(semantic matching features), &#x6539;&#x5199;(query rewriting)&#x3002;&#x7ED9;&#x51FA;&#x4E86;&#x68C0;&#x7D22;&#x7ED3;&#x679C;&#x540C;&#x65F6;&#x6EE1;&#x8DB3;&#x65F6;&#x6548;&#x6027;&#x548C;&#x5730;&#x7406;&#x4F4D;&#x7F6E;&#x76F8;&#x5173;&#x5EA6;&#x7684;&#x89E3;&#x51B3;&#x65B9;&#x6848;&#x3002;</p></div><p class="readmore"><a href="/2016/09/13/Ranking-Relevance-in-Yahoo-Search/">阅读更多</a></p></div><nav class="page-navigator"><span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/">下一页</a></nav></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form action="//www.baidu.com/baidu" method="get" accept-charset="utf-8" target="_blank" class="search-form"><input type="search" name="word" maxlength="20" placeholder="Search"/><input type="hidden" name="si" value="https://mlnote.com"/><input name="tn" type="hidden" value="bds"/><input name="cl" type="hidden" value="3"/><input name="ct" type="hidden" value="2097152"/><input name="s" type="hidden" value="on"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/其他/">其他</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/">机器学习</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/gbdt/" style="font-size: 15px;">gbdt</a> <a href="/tags/Batch-Normalization/" style="font-size: 15px;">Batch Normalization</a> <a href="/tags/neural-networks/" style="font-size: 15px;">neural-networks</a> <a href="/tags/neural-networks/" style="font-size: 15px;">neural networks</a> <a href="/tags/word-embedding/" style="font-size: 15px;">word embedding</a> <a href="/tags/learning-to-rank/" style="font-size: 15px;">learning to rank</a> <a href="/tags/query-rewriting/" style="font-size: 15px;">query rewriting</a> <a href="/tags/semantic-matching/" style="font-size: 15px;">semantic matching</a> <a href="/tags/deep-learning/" style="font-size: 15px;">deep learning</a> <a href="/tags/SyntaxNet/" style="font-size: 15px;">SyntaxNet</a> <a href="/tags/CRF/" style="font-size: 15px;">CRF</a> <a href="/tags/user-targeting/" style="font-size: 15px;">user targeting</a> <a href="/tags/advertisement/" style="font-size: 15px;">advertisement</a> <a href="/tags/RBMs/" style="font-size: 15px;">RBMs</a> <a href="/tags/fastBDT/" style="font-size: 15px;">fastBDT</a> <a href="/tags/Caffe/" style="font-size: 15px;">Caffe</a> <a href="/tags/lightGBM/" style="font-size: 15px;">lightGBM</a> <a href="/tags/gradient-boosting-framework/" style="font-size: 15px;">gradient boosting framework</a> <a href="/tags/huber/" style="font-size: 15px;">huber</a> <a href="/tags/LST/" style="font-size: 15px;">LST</a> <a href="/tags/LAD/" style="font-size: 15px;">LAD</a> <a href="/tags/classify/" style="font-size: 15px;">classify</a> <a href="/tags/xgboost/" style="font-size: 15px;">xgboost</a> <a href="/tags/code-mannar/" style="font-size: 15px;">code mannar</a> <a href="/tags/gbRank/" style="font-size: 15px;">gbRank</a> <a href="/tags/logisticRank/" style="font-size: 15px;">logisticRank</a> <a href="/tags/hexo/" style="font-size: 15px;">hexo</a> <a href="/tags/mathjex-公式/" style="font-size: 15px;">mathjex 公式</a> <a href="/tags/model/" style="font-size: 15px;">model</a> <a href="/tags/bayes/" style="font-size: 15px;">bayes</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2016/12/20/Neural-Network-Batch-Normalization-and-Caffe-Code/">浅谈Batch Normalization及其Caffe实现</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/12/18/Reading-Notes-of-Word-Embedding/">Word Embedding札记</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/12/10/SyntaxNet Neural-Models-of-Syntax/">简介语法分析开源神经网络SyntaxNet</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/11/18/The-realization-of-GBDT-in-LightGBM-and-FastDBT/">简述FastDBT和LightGBM中GBDT的实现</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/10/29/xgboost-code-review-with-paper/">XGboost核心源码阅读</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/10/05/a-guide-to-xgboost-A-Scalable-Tree-Boosting-System/">XGboost: A Scalable Tree Boosting System论文及源码导读</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/10/02/gradient-boosting-decision-tree-2/">Gradient Boosting Decision Tree[下篇]</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/09/24/gradient-boosting-decision-tree-1/">Gradient Boosting Decision Tree[上篇]</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/09/18/gbRank-logsitRank-from-up-to-bottom/">gbRank & logsitcRank自顶向下</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/09/13/Ranking-Relevance-in-Yahoo-Search/">[笔记]Ranking Relevance in Yahoo Search</a></li></ul></div><div class="widget"><div class="comments-title"><i class="fa fa-comment-o"> 最近评论</i></div><div data-num-items="5" data-show-avatars="0" data-show-time="1" data-show-admin="0" data-excerpt-length="32" data-show-title="1" class="ds-recent-comments"></div></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://www.example1.com/" title="site-name1" target="_blank">site-name1</a><ul></ul><a href="http://www.example2.com/" title="site-name2" target="_blank">site-name2</a><ul></ul><a href="http://www.example3.com/" title="site-name3" target="_blank">site-name3</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">© <a href="/." rel="nofollow">水滴石穿.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.pack.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="/css/jquery.fancybox.css?v=0.0.0"><script>var duoshuoQuery = {short_name:'qiugen'};
(function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0]
        || document.getElementsByTagName('body')[0]).appendChild(ds);
})();
</script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?ceebf89bb3d2a3b32aff294e42be4ed7";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
  })();
</script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>